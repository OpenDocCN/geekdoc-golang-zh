<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Benchmarking and Load Testing for Networked Go Apps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Benchmarking and Load Testing for Networked Go Apps</h1>
<blockquote>原文：<a href="https://goperf.dev/02-networking/bench-and-load/">https://goperf.dev/02-networking/bench-and-load/</a></blockquote>
                
                  


  
  



<p>Before you reach for a mutex-free queue or tune your goroutine pool, step back. Optimization without a baseline is just guesswork. In Go applications, performance tuning starts with understanding how your system behaves under pressure, which means benchmarking it under load.</p>
<p>Load testing isn't just about pushing requests until things break. It's about simulating realistic usage patterns to extract measurable, repeatable data. That data anchors every optimization that follows.</p>
<h2 id="test-app-simulating-fastslow-paths-and-gc-pressure">Test App: Simulating Fast/Slow Paths and GC pressure</h2>
<p>To benchmark meaningfully, we need endpoints that reflect different workload characteristics.</p>
<details class="example">
<summary>Show the benchmarking app</summary>
<div class="highlight"><pre><span/><code><span class="kn">package</span><span class="w"> </span><span class="nx">main</span>

<span class="c1">// pprof-start</span>
<span class="kn">import</span><span class="w"> </span><span class="p">(</span>
<span class="c1">// pprof-end</span>
<span class="w">    </span><span class="s">"flag"</span>
<span class="w">    </span><span class="s">"fmt"</span>
<span class="w">    </span><span class="s">"log"</span>
<span class="w">    </span><span class="s">"math/rand/v2"</span>
<span class="w">    </span><span class="s">"net/http"</span>
<span class="c1">// pprof-start</span>
<span class="w">    </span><span class="nx">_</span><span class="w"> </span><span class="s">"net/http/pprof"</span>
<span class="c1">// pprof-end</span>
<span class="w">    </span><span class="s">"os"</span>
<span class="w">    </span><span class="s">"os/signal"</span>
<span class="w">    </span><span class="s">"time"</span>
<span class="c1">// pprof-start</span>
<span class="p">)</span>
<span class="c1">// pprof-end</span>

<span class="kd">var</span><span class="w"> </span><span class="p">(</span>
<span class="w">    </span><span class="nx">fastDelay</span><span class="w">   </span><span class="p">=</span><span class="w"> </span><span class="nx">flag</span><span class="p">.</span><span class="nx">Duration</span><span class="p">(</span><span class="s">"fast-delay"</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="s">"Fixed delay for fast handler (if any)"</span><span class="p">)</span>
<span class="w">    </span><span class="nx">slowMin</span><span class="w">     </span><span class="p">=</span><span class="w"> </span><span class="nx">flag</span><span class="p">.</span><span class="nx">Duration</span><span class="p">(</span><span class="s">"slow-min"</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">*</span><span class="nx">time</span><span class="p">.</span><span class="nx">Millisecond</span><span class="p">,</span><span class="w"> </span><span class="s">"Minimum delay for slow handler"</span><span class="p">)</span>
<span class="w">    </span><span class="nx">slowMax</span><span class="w">     </span><span class="p">=</span><span class="w"> </span><span class="nx">flag</span><span class="p">.</span><span class="nx">Duration</span><span class="p">(</span><span class="s">"slow-max"</span><span class="p">,</span><span class="w"> </span><span class="mi">300</span><span class="o">*</span><span class="nx">time</span><span class="p">.</span><span class="nx">Millisecond</span><span class="p">,</span><span class="w"> </span><span class="s">"Maximum delay for slow handler"</span><span class="p">)</span>
<span class="w">    </span><span class="nx">gcMinAlloc</span><span class="w">  </span><span class="p">=</span><span class="w"> </span><span class="nx">flag</span><span class="p">.</span><span class="nx">Int</span><span class="p">(</span><span class="s">"gc-min-alloc"</span><span class="p">,</span><span class="w"> </span><span class="mi">50</span><span class="p">,</span><span class="w"> </span><span class="s">"Minimum number of allocations in GC heavy handler"</span><span class="p">)</span>
<span class="w">    </span><span class="nx">gcMaxAlloc</span><span class="w">  </span><span class="p">=</span><span class="w"> </span><span class="nx">flag</span><span class="p">.</span><span class="nx">Int</span><span class="p">(</span><span class="s">"gc-max-alloc"</span><span class="p">,</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span><span class="w"> </span><span class="s">"Maximum number of allocations in GC heavy handler"</span><span class="p">)</span>
<span class="p">)</span>

<span class="kd">func</span><span class="w"> </span><span class="nx">randRange</span><span class="p">(</span><span class="nx">min</span><span class="p">,</span><span class="w"> </span><span class="nx">max</span><span class="w"> </span><span class="kt">int</span><span class="p">)</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">rand</span><span class="p">.</span><span class="nx">IntN</span><span class="p">(</span><span class="nx">max</span><span class="o">-</span><span class="nx">min</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">min</span>
<span class="p">}</span>

<span class="kd">func</span><span class="w"> </span><span class="nx">fastHandler</span><span class="p">(</span><span class="nx">w</span><span class="w"> </span><span class="nx">http</span><span class="p">.</span><span class="nx">ResponseWriter</span><span class="p">,</span><span class="w"> </span><span class="nx">r</span><span class="w"> </span><span class="o">*</span><span class="nx">http</span><span class="p">.</span><span class="nx">Request</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">*</span><span class="nx">fastDelay</span><span class="w"> </span><span class="p">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nx">time</span><span class="p">.</span><span class="nx">Sleep</span><span class="p">(</span><span class="o">*</span><span class="nx">fastDelay</span><span class="p">)</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Fprintln</span><span class="p">(</span><span class="nx">w</span><span class="p">,</span><span class="w"> </span><span class="s">"fast response"</span><span class="p">)</span>
<span class="p">}</span>

<span class="kd">func</span><span class="w"> </span><span class="nx">slowHandler</span><span class="p">(</span><span class="nx">w</span><span class="w"> </span><span class="nx">http</span><span class="p">.</span><span class="nx">ResponseWriter</span><span class="p">,</span><span class="w"> </span><span class="nx">r</span><span class="w"> </span><span class="o">*</span><span class="nx">http</span><span class="p">.</span><span class="nx">Request</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">delayRange</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nb">int</span><span class="p">((</span><span class="o">*</span><span class="nx">slowMax</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="o">*</span><span class="nx">slowMin</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nx">time</span><span class="p">.</span><span class="nx">Millisecond</span><span class="p">)</span>
<span class="w">    </span><span class="nx">delay</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">time</span><span class="p">.</span><span class="nx">Duration</span><span class="p">(</span><span class="nx">randRange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="nx">delayRange</span><span class="p">))</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">time</span><span class="p">.</span><span class="nx">Millisecond</span>
<span class="w">    </span><span class="nx">time</span><span class="p">.</span><span class="nx">Sleep</span><span class="p">(</span><span class="nx">delay</span><span class="p">)</span>
<span class="w">    </span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Fprintf</span><span class="p">(</span><span class="nx">w</span><span class="p">,</span><span class="w"> </span><span class="s">"slow response with delay %d ms\n"</span><span class="p">,</span><span class="w"> </span><span class="nx">delay</span><span class="p">.</span><span class="nx">Milliseconds</span><span class="p">())</span>
<span class="p">}</span>

<span class="c1">// heavy-start</span>
<span class="kd">var</span><span class="w"> </span><span class="nx">longLivedData</span><span class="w"> </span><span class="p">[][]</span><span class="kt">byte</span>

<span class="kd">func</span><span class="w"> </span><span class="nx">gcHeavyHandler</span><span class="p">(</span><span class="nx">w</span><span class="w"> </span><span class="nx">http</span><span class="p">.</span><span class="nx">ResponseWriter</span><span class="p">,</span><span class="w"> </span><span class="nx">r</span><span class="w"> </span><span class="o">*</span><span class="nx">http</span><span class="p">.</span><span class="nx">Request</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">numAllocs</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">randRange</span><span class="p">(</span><span class="o">*</span><span class="nx">gcMinAlloc</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="nx">gcMaxAlloc</span><span class="p">)</span>
<span class="w">    </span><span class="kd">var</span><span class="w"> </span><span class="nx">data</span><span class="w"> </span><span class="p">[][]</span><span class="kt">byte</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="p">&lt;</span><span class="w"> </span><span class="nx">numAllocs</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="o">++</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// Allocate 10KB slices. Occasionally retain a reference to simulate long-lived objects.</span>
<span class="w">        </span><span class="nx">b</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nb">make</span><span class="p">([]</span><span class="kt">byte</span><span class="p">,</span><span class="w"> </span><span class="mi">1024</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
<span class="w">        </span><span class="nx">data</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nb">append</span><span class="p">(</span><span class="nx">data</span><span class="p">,</span><span class="w"> </span><span class="nx">b</span><span class="p">)</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nx">i</span><span class="o">%</span><span class="mi">100</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1">// every 100 allocations, keep the data alive</span>
<span class="w">            </span><span class="nx">longLivedData</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nb">append</span><span class="p">(</span><span class="nx">longLivedData</span><span class="p">,</span><span class="w"> </span><span class="nx">b</span><span class="p">)</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Fprintf</span><span class="p">(</span><span class="nx">w</span><span class="p">,</span><span class="w"> </span><span class="s">"allocated %d KB\n"</span><span class="p">,</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="nx">data</span><span class="p">)</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
<span class="p">}</span>
<span class="c1">// heavy-end</span>

<span class="kd">func</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nx">flag</span><span class="p">.</span><span class="nx">Parse</span><span class="p">()</span>

<span class="w">    </span><span class="nx">http</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">"/fast"</span><span class="p">,</span><span class="w"> </span><span class="nx">fastHandler</span><span class="p">)</span>
<span class="w">    </span><span class="nx">http</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">"/slow"</span><span class="p">,</span><span class="w"> </span><span class="nx">slowHandler</span><span class="p">)</span>
<span class="w">    </span><span class="nx">http</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">"/gc"</span><span class="p">,</span><span class="w"> </span><span class="nx">gcHeavyHandler</span><span class="p">)</span>

<span class="c1">// pprof-start</span>
<span class="c1">// ...</span>

<span class="w">    </span><span class="c1">// Start pprof in a separate goroutine.</span>
<span class="w">    </span><span class="k">go</span><span class="w"> </span><span class="kd">func</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nx">log</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"pprof listening on :6060"</span><span class="p">)</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">http</span><span class="p">.</span><span class="nx">ListenAndServe</span><span class="p">(</span><span class="s">"localhost:6060"</span><span class="p">,</span><span class="w"> </span><span class="kc">nil</span><span class="p">);</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="kc">nil</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nx">log</span><span class="p">.</span><span class="nx">Fatalf</span><span class="p">(</span><span class="s">"pprof server error: %v"</span><span class="p">,</span><span class="w"> </span><span class="nx">err</span><span class="p">)</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}()</span>
<span class="c1">// pprof-end</span>

<span class="w">    </span><span class="c1">// Create a server to allow for graceful shutdown.</span>
<span class="w">    </span><span class="nx">server</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="o">&amp;</span><span class="nx">http</span><span class="p">.</span><span class="nx">Server</span><span class="p">{</span><span class="nx">Addr</span><span class="p">:</span><span class="w"> </span><span class="s">":8080"</span><span class="p">}</span>

<span class="w">    </span><span class="k">go</span><span class="w"> </span><span class="kd">func</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nx">log</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"HTTP server listening on :8080"</span><span class="p">)</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">server</span><span class="p">.</span><span class="nx">ListenAndServe</span><span class="p">();</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="kc">nil</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="nx">http</span><span class="p">.</span><span class="nx">ErrServerClosed</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nx">log</span><span class="p">.</span><span class="nx">Fatalf</span><span class="p">(</span><span class="s">"HTTP server error: %v"</span><span class="p">,</span><span class="w"> </span><span class="nx">err</span><span class="p">)</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}()</span>

<span class="w">    </span><span class="c1">// Graceful shutdown on interrupt signal.</span>
<span class="w">    </span><span class="nx">sigCh</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nb">make</span><span class="p">(</span><span class="kd">chan</span><span class="w"> </span><span class="nx">os</span><span class="p">.</span><span class="nx">Signal</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="w">    </span><span class="nx">signal</span><span class="p">.</span><span class="nx">Notify</span><span class="p">(</span><span class="nx">sigCh</span><span class="p">,</span><span class="w"> </span><span class="nx">os</span><span class="p">.</span><span class="nx">Interrupt</span><span class="p">)</span>
<span class="w">    </span><span class="o">&lt;-</span><span class="nx">sigCh</span>
<span class="w">    </span><span class="nx">log</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"Shutting down server..."</span><span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">server</span><span class="p">.</span><span class="nx">Shutdown</span><span class="p">(</span><span class="kc">nil</span><span class="p">);</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="kc">nil</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nx">log</span><span class="p">.</span><span class="nx">Fatalf</span><span class="p">(</span><span class="s">"Server Shutdown Failed:%+v"</span><span class="p">,</span><span class="w"> </span><span class="nx">err</span><span class="p">)</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="nx">log</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"Server exited"</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div>
</details>
<ul>
<li><code>/fast</code>: A quick response, ideal for throughput testing.</li>
<li><code>/slow</code>: Simulates latency and contention.</li>
<li><code>/gc</code>: Simulate GC heavy workflow.</li>
<li><code>net/http/pprof</code>: Exposes runtime profiling on <code>localhost:6060</code>.</li>
</ul>
<p>Run it with:</p>
<div class="highlight"><pre><span/><code>go<span class="w"> </span>run<span class="w"> </span>main.go
</code></pre></div>
<h2 id="simulating-load-tools-that-reflect-reality">Simulating Load: Tools That Reflect Reality</h2>
<h3 id="when-to-use-what">When to Use What</h3>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>This is by no means an exhaustive list. The ecosystem of load-testing tools is broad and constantly evolving. Tools like Apache JMeter, Locust, Artillery, and Gatling each bring their own strengths—ranging from UI-driven test design to distributed execution or JVM-based scenarios. The right choice depends on your stack, test goals, and team workflow. The tools listed here are optimized for Go-based services and local-first benchmarking, but they’re just a starting point.</p>
</div>
<p>At a glance, <code>vegeta</code>, <code>wrk</code>, and <code>k6</code> all hammer HTTP endpoints. But they serve different roles depending on what you're testing, how much precision you need, and how complex your scenario is.</p>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Focus</th>
<th>Scriptable</th>
<th>Metrics Depth</th>
<th>Ideal Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>vegeta</code></td>
<td>Constant rate load generation</td>
<td>No (but composable)</td>
<td>High (histogram, percentiles)</td>
<td>Tracking latency percentiles over time; CI benchmarking</td>
</tr>
<tr>
<td><code>wrk</code></td>
<td>Max throughput stress tests</td>
<td>Yes (Lua)</td>
<td>Medium</td>
<td>Measuring raw server capacity and concurrency limits</td>
</tr>
<tr>
<td><code>k6</code></td>
<td>Scenario-based simulation</td>
<td>Yes (JavaScript)</td>
<td>High (VU metrics, dashboards)</td>
<td>Simulating real-world user workflows and pacing</td>
</tr>
</tbody>
</table>
<p>Use <code>vegeta</code> when:</p>
<ul>
<li>You need a consistent RPS load (e.g., 100 requests/sec for the 60s).</li>
<li>You're observing latency degradation under controlled pressure.</li>
<li>You want structured output (histograms, percentiles) for profiling.</li>
<li>You want to verify local changes before deeper profiling.</li>
</ul>
<p>Use <code>wrk</code> when:</p>
<ul>
<li>You're exploring upper-bound throughput.</li>
<li>You want raw, fast load with minimal setup.</li>
<li>You’re profiling at high concurrency (e.g., 10k connections).</li>
</ul>
<p>Use <code>k6</code> when:</p>
<ul>
<li>You must model complex flows like login → API call → wait → logout.</li>
<li>You’re integrating performance tests into CI/CD.</li>
<li>You want thresholds, pacing, and visual feedback.</li>
</ul>
<p>Each of these tools has a place in your benchmarking toolkit. Picking the right one depends on whether you're validating performance, exploring scaling thresholds, or simulating end-user behavior.</p>
<h3 id="vegeta">Vegeta</h3>
<p><a href="https://github.com/tsenart/vegeta">Vegeta</a> is a flexible HTTP load testing tool written in Go, built for generating constant request rates. This makes it well-suited for simulating steady, sustained traffic patterns instead of sudden spikes.</p>
<p>We reach for Vegeta when precision matters. It maintains exact request rates and captures detailed latency distributions, which helps track how system behavior changes under load. It’s lightweight, easy to automate, and integrates cleanly into CI workflows—making it a reliable option for benchmarking Go services.</p>
<p>Install:</p>
<div class="highlight"><pre><span/><code>go<span class="w"> </span>install<span class="w"> </span>github.com/tsenart/vegeta@latest
</code></pre></div>
<p>Which endpoint(s) we are going to test:</p>
<div class="highlight"><pre><span/><code><span class="nb">echo</span><span class="w"> </span><span class="s2">"GET http://localhost:8080/slow"</span><span class="w"> </span>&gt;<span class="w"> </span>targets.txt
</code></pre></div>
<p>Run:</p>
<div class="highlight"><pre><span/><code>vegeta<span class="w"> </span>attack<span class="w"> </span>-rate<span class="o">=</span><span class="m">100</span><span class="w"> </span>-duration<span class="o">=</span>30s<span class="w"> </span>-targets<span class="o">=</span>targets.txt<span class="w"> </span><span class="p">|</span><span class="w"> </span>tee<span class="w"> </span>results.bin<span class="w"> </span><span class="p">|</span><span class="w"> </span>vegeta<span class="w"> </span>report
</code></pre></div>
<details class="example">
<summary>Potential output</summary>
<div class="highlight"><pre><span/><code>&gt;<span class="w"> </span>vegeta<span class="w"> </span>attack<span class="w"> </span>-rate<span class="o">=</span><span class="m">100</span><span class="w"> </span>-duration<span class="o">=</span>30s<span class="w"> </span>-targets<span class="o">=</span>targets.txt<span class="w"> </span><span class="p">|</span><span class="w"> </span>tee<span class="w"> </span>results.bin<span class="w"> </span><span class="p">|</span><span class="w"> </span>vegeta<span class="w"> </span>report
Requests<span class="w">      </span><span class="o">[</span>total,<span class="w"> </span>rate,<span class="w"> </span>throughput<span class="o">]</span><span class="w">  </span><span class="m">3000</span>,<span class="w"> </span><span class="m">100</span>.04,<span class="w"> </span><span class="m">100</span>.03
Duration<span class="w">      </span><span class="o">[</span>total,<span class="w"> </span>attack,<span class="w"> </span>wait<span class="o">]</span><span class="w">      </span><span class="m">29</span>.989635542s,<span class="w"> </span><span class="m">29</span>.989108333s,<span class="w"> </span><span class="m">527</span>.209µs
Latencies<span class="w">     </span><span class="o">[</span>mean,<span class="w"> </span><span class="m">50</span>,<span class="w"> </span><span class="m">95</span>,<span class="w"> </span><span class="m">99</span>,<span class="w"> </span>max<span class="o">]</span><span class="w">    </span><span class="m">524</span>.563µs,<span class="w"> </span><span class="m">504</span>.802µs,<span class="w"> </span><span class="m">793</span>.997µs,<span class="w"> </span><span class="m">1</span>.47362ms,<span class="w"> </span><span class="m">7</span>.351541ms
Bytes<span class="w"> </span>In<span class="w">      </span><span class="o">[</span>total,<span class="w"> </span>mean<span class="o">]</span><span class="w">              </span><span class="m">42000</span>,<span class="w"> </span><span class="m">14</span>.00
Bytes<span class="w"> </span>Out<span class="w">     </span><span class="o">[</span>total,<span class="w"> </span>mean<span class="o">]</span><span class="w">              </span><span class="m">0</span>,<span class="w"> </span><span class="m">0</span>.00
Success<span class="w">       </span><span class="o">[</span>ratio<span class="o">]</span><span class="w">                    </span><span class="m">100</span>.00%
Status<span class="w"> </span>Codes<span class="w">  </span><span class="o">[</span>code:count<span class="o">]</span><span class="w">               </span><span class="m">200</span>:3000
Error<span class="w"> </span>Set:
</code></pre></div>
</details>
<p>View percentiles:</p>
<div class="highlight"><pre><span/><code>vegeta<span class="w"> </span>report<span class="w"> </span>-type<span class="o">=</span><span class="s1">'hist[0,10ms,50ms,100ms,200ms,500ms,1s]'</span><span class="w"> </span>&lt;<span class="w"> </span>results.bin
</code></pre></div>
<p>Generate chart:</p>
<div class="highlight"><pre><span/><code>vegeta<span class="w"> </span>plot<span class="w"> </span>&lt;<span class="w"> </span>results.bin<span class="w"> </span>&gt;<span class="w"> </span>plot.html
</code></pre></div>
<details class="info">
<summary>Testing Multiple Endpoints with Vegeta</summary>
<p>Depending on your goals, there are two recommended approaches for testing both <code>/fast</code> and <code>/slow</code> endpoints in a single run.</p>
<p><strong>Option 1: Round-Robin Between Endpoints</strong></p>
<p>Create a <code>targets.txt</code> with both endpoints:</p>
<div class="highlight"><pre><span/><code>cat<span class="w"> </span>&gt;<span class="w"> </span>targets.txt<span class="w"> </span><span class="s">&lt;&lt;EOF</span>
<span class="s">GET http://localhost:8080/fast</span>
<span class="s">GET http://localhost:8080/slow</span>
<span class="s">EOF</span>
</code></pre></div>
<p>Run the test:</p>
<div class="highlight"><pre><span/><code>vegeta<span class="w"> </span>attack<span class="w"> </span>-rate<span class="o">=</span><span class="m">50</span><span class="w"> </span>-duration<span class="o">=</span>30s<span class="w"> </span>-targets<span class="o">=</span>targets.txt<span class="w"> </span><span class="p">|</span><span class="w"> </span>tee<span class="w"> </span>mixed-results.bin<span class="w"> </span><span class="p">|</span><span class="w"> </span>vegeta<span class="w"> </span>report<span class="w"> </span>-type<span class="o">=</span><span class="s1">'hist[0,50ms,100ms,200ms,500ms,1s,2s]'</span>
</code></pre></div>
<ul>
<li>Requests are randomly distributed between the two endpoints.</li>
<li>Useful for observing aggregate behavior of mixed traffic.</li>
<li>Easy to set up and analyze combined performance.</li>
</ul>
<p><strong>Option 2: Weighted Mix Using Multiple Vegeta Runs</strong></p>
<p>To simulate different traffic proportions (e.g., 80% fast, 20% slow):</p>
<div class="highlight"><pre><span/><code><span class="c1"># Send 80% of requests to /fast</span>
vegeta<span class="w"> </span>attack<span class="w"> </span>-rate<span class="o">=</span><span class="m">40</span><span class="w"> </span>-duration<span class="o">=</span>30s<span class="w"> </span>-targets<span class="o">=</span>&lt;<span class="o">(</span><span class="nb">echo</span><span class="w"> </span><span class="s2">"GET http://localhost:8080/fast"</span><span class="o">)</span><span class="w"> </span>&gt;<span class="w"> </span>fast.bin<span class="w"> </span><span class="p">&amp;</span>

<span class="c1"># Send 20% of requests to /slow</span>
vegeta<span class="w"> </span>attack<span class="w"> </span>-rate<span class="o">=</span><span class="m">10</span><span class="w"> </span>-duration<span class="o">=</span>30s<span class="w"> </span>-targets<span class="o">=</span>&lt;<span class="o">(</span><span class="nb">echo</span><span class="w"> </span><span class="s2">"GET http://localhost:8080/slow"</span><span class="o">)</span><span class="w"> </span>&gt;<span class="w"> </span>slow.bin<span class="w"> </span><span class="p">&amp;</span>

<span class="nb">wait</span>
</code></pre></div>
<p>Then merge the results and generate a report:</p>
<div class="highlight"><pre><span/><code>vegeta<span class="w"> </span>encode<span class="w"> </span>fast.bin<span class="w"> </span>slow.bin<span class="w"> </span>&gt;<span class="w"> </span>combined.bin
vegeta<span class="w"> </span>report<span class="w"> </span>-type<span class="o">=</span><span class="s1">'hist[0,50ms,100ms,200ms,500ms,1s,2s]'</span><span class="w"> </span>&lt;<span class="w"> </span>combined.bin
</code></pre></div>
<ul>
<li>Gives you precise control over traffic distribution.</li>
<li>Better for simulating realistic traffic mixes.</li>
<li>Enables per-endpoint benchmarking when analyzed separately.</li>
</ul>
<p>Both methods are valid—choose based on whether you need simplicity or control.</p>
</details>
<h3 id="wrk">wrk</h3>
<p><a href="https://github.com/wg/wrk">wrk</a> is a high-performance HTTP benchmarking tool written in C. It's designed for raw speed and concurrency, making it ideal for stress testing your server’s throughput and connection handling capacity.</p>
<p>We use <code>wrk</code> when we want to push the system to its upper limits. It excels at flooding endpoints with high request volumes using multiple threads and connections. While it doesn’t offer detailed percentiles like <code>vegeta</code>, it's perfect for quick saturation tests and measuring how much traffic your Go server can handle before it starts dropping requests or stalling.</p>
<p>Install:</p>
<div class="highlight"><pre><span/><code>brew<span class="w"> </span>install<span class="w"> </span>wrk<span class="w">  </span><span class="c1"># or build from source</span>
</code></pre></div>
<p>Run test:</p>
<div class="highlight"><pre><span/><code>wrk<span class="w"> </span>-t4<span class="w"> </span>-c100<span class="w"> </span>-d30s<span class="w"> </span>http://localhost:8080/fast
</code></pre></div>
<details class="example">
<summary>Potential output</summary>
<div class="highlight"><pre><span/><code>&gt;<span class="w"> </span>wrk<span class="w"> </span>-t4<span class="w"> </span>-c100<span class="w"> </span>-d30s<span class="w"> </span>http://localhost:8080/fast
Running<span class="w"> </span>30s<span class="w"> </span><span class="nb">test</span><span class="w"> </span>@<span class="w"> </span>http://localhost:8080/fast
<span class="w">  </span><span class="m">4</span><span class="w"> </span>threads<span class="w"> </span>and<span class="w"> </span><span class="m">100</span><span class="w"> </span>connections
<span class="w">  </span>Thread<span class="w"> </span>Stats<span class="w">   </span>Avg<span class="w">      </span>Stdev<span class="w">     </span>Max<span class="w">   </span>+/-<span class="w"> </span>Stdev
<span class="w">    </span>Latency<span class="w">     </span><span class="m">1</span>.29ms<span class="w">  </span><span class="m">255</span>.31us<span class="w">   </span><span class="m">5</span>.24ms<span class="w">   </span><span class="m">84</span>.86%
<span class="w">    </span>Req/Sec<span class="w">    </span><span class="m">19</span>.30k<span class="w">   </span><span class="m">565</span>.16<span class="w">    </span><span class="m">21</span>.93k<span class="w">    </span><span class="m">77</span>.92%
<span class="w">  </span><span class="m">2304779</span><span class="w"> </span>requests<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">30</span>.00s,<span class="w"> </span><span class="m">287</span>.94MB<span class="w"> </span><span class="nb">read</span>
Requests/sec:<span class="w">  </span><span class="m">76823</span>.88
Transfer/sec:<span class="w">      </span><span class="m">9</span>.60MB
</code></pre></div>
</details>
<h3 id="k6">k6</h3>
<p><a href="https://k6.io">k6</a> is a modern load testing tool built around scripting realistic client behavior in JavaScript. It’s designed for simulating time-based load profiles—ramp-up, steady-state, ramp-down—and supports custom flows, pacing, and threshold-based validation.</p>
<p>We use <code>k6</code> when raw throughput isn’t enough and we need to simulate how real users interact with the system. It handles chained requests, models session-like flows, and supports stage-based testing out of the box. With rich metrics and seamless CI/CD integration, <code>k6</code> helps surface regressions before they reach production.</p>
<p>Install:</p>
<div class="highlight"><pre><span/><code>brew<span class="w"> </span>install<span class="w"> </span>k6
</code></pre></div>
<p>Script:</p>
<div class="highlight"><pre><span/><code><span class="c1">// script.js</span>
<span class="k">import</span><span class="w"> </span><span class="nx">http</span><span class="w"> </span><span class="kr">from</span><span class="w"> </span><span class="s1">'k6/http'</span><span class="p">;</span>
<span class="k">import</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nx">sleep</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="kr">from</span><span class="w"> </span><span class="s1">'k6'</span><span class="p">;</span>

<span class="k">export</span><span class="w"> </span><span class="kd">const</span><span class="w"> </span><span class="nx">options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nx">stages</span><span class="o">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">duration</span><span class="o">:</span><span class="w"> </span><span class="s1">'10s'</span><span class="p">,</span><span class="w"> </span><span class="nx">target</span><span class="o">:</span><span class="w"> </span><span class="mf">50</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">duration</span><span class="o">:</span><span class="w"> </span><span class="s1">'30s'</span><span class="p">,</span><span class="w"> </span><span class="nx">target</span><span class="o">:</span><span class="w"> </span><span class="mf">50</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nx">duration</span><span class="o">:</span><span class="w"> </span><span class="s1">'10s'</span><span class="p">,</span><span class="w"> </span><span class="nx">target</span><span class="o">:</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="p">},</span>
<span class="w">  </span><span class="p">],</span>
<span class="p">};</span>

<span class="k">export</span><span class="w"> </span><span class="k">default</span><span class="w"> </span><span class="kd">function</span><span class="w"> </span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nx">http</span><span class="p">.</span><span class="nx">get</span><span class="p">(</span><span class="s1">'http://localhost:8080/fast'</span><span class="p">);</span>
<span class="w">  </span><span class="nx">sleep</span><span class="p">(</span><span class="mf">1</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>
<p>Run:</p>
<div class="highlight"><pre><span/><code>k6<span class="w"> </span>run<span class="w"> </span>script.js
</code></pre></div>
<details class="example">
<summary>Potential output</summary>
<div class="highlight"><pre><span/><code>&gt;<span class="w"> </span>k6<span class="w"> </span>run<span class="w"> </span>script.js

<span class="w">         </span>/<span class="se">\ </span><span class="w">     </span>Grafana<span class="w">   </span>/‾‾/
<span class="w">    </span>/<span class="se">\ </span><span class="w"> </span>/<span class="w">  </span><span class="se">\ </span><span class="w">    </span><span class="p">|</span><span class="se">\ </span><span class="w"> </span>__<span class="w">   </span>/<span class="w">  </span>/
<span class="w">   </span>/<span class="w">  </span><span class="se">\/</span><span class="w">    </span><span class="se">\ </span><span class="w">   </span><span class="p">|</span><span class="w"> </span><span class="p">|</span>/<span class="w"> </span>/<span class="w">  </span>/<span class="w">   </span>‾‾<span class="se">\</span>
<span class="w">  </span>/<span class="w">          </span><span class="se">\ </span><span class="w">  </span><span class="p">|</span><span class="w">   </span><span class="o">(</span><span class="w">  </span><span class="p">|</span><span class="w">  </span><span class="o">(</span>‾<span class="o">)</span><span class="w">  </span><span class="p">|</span>
<span class="w"> </span>/<span class="w"> </span>__________<span class="w"> </span><span class="se">\ </span><span class="w"> </span><span class="p">|</span>_<span class="p">|</span><span class="se">\_\ </span><span class="w"> </span><span class="se">\_</span>____/

<span class="w">     </span>execution:<span class="w"> </span><span class="nb">local</span>
<span class="w">        </span>script:<span class="w"> </span>script.js
<span class="w">        </span>output:<span class="w"> </span>-

<span class="w">     </span>scenarios:<span class="w"> </span><span class="o">(</span><span class="m">100</span>.00%<span class="o">)</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>scenario,<span class="w"> </span><span class="m">50</span><span class="w"> </span>max<span class="w"> </span>VUs,<span class="w"> </span>1m20s<span class="w"> </span>max<span class="w"> </span>duration<span class="w"> </span><span class="o">(</span>incl.<span class="w"> </span>graceful<span class="w"> </span>stop<span class="o">)</span>:
<span class="w">              </span>*<span class="w"> </span>default:<span class="w"> </span>Up<span class="w"> </span>to<span class="w"> </span><span class="m">50</span><span class="w"> </span>looping<span class="w"> </span>VUs<span class="w"> </span><span class="k">for</span><span class="w"> </span>50s<span class="w"> </span>over<span class="w"> </span><span class="m">3</span><span class="w"> </span>stages<span class="w"> </span><span class="o">(</span>gracefulRampDown:<span class="w"> </span>30s,<span class="w"> </span>gracefulStop:<span class="w"> </span>30s<span class="o">)</span>


<span class="w">  </span>█<span class="w"> </span>TOTAL<span class="w"> </span>RESULTS

<span class="w">    </span>HTTP
<span class="w">    </span>http_req_duration.......................................................:<span class="w"> </span><span class="nv">avg</span><span class="o">=</span><span class="m">495</span>.55µs<span class="w"> </span><span class="nv">min</span><span class="o">=</span>116µs<span class="w"> </span><span class="nv">med</span><span class="o">=</span>449µs<span class="w"> </span><span class="nv">max</span><span class="o">=</span><span class="m">5</span>.49ms<span class="w"> </span>p<span class="o">(</span><span class="m">90</span><span class="o">)=</span>705µs<span class="w"> </span>p<span class="o">(</span><span class="m">95</span><span class="o">)=</span><span class="m">820</span>.39µs
<span class="w">      </span><span class="o">{</span><span class="w"> </span>expected_response:true<span class="w"> </span><span class="o">}</span>............................................:<span class="w"> </span><span class="nv">avg</span><span class="o">=</span><span class="m">495</span>.55µs<span class="w"> </span><span class="nv">min</span><span class="o">=</span>116µs<span class="w"> </span><span class="nv">med</span><span class="o">=</span>449µs<span class="w"> </span><span class="nv">max</span><span class="o">=</span><span class="m">5</span>.49ms<span class="w"> </span>p<span class="o">(</span><span class="m">90</span><span class="o">)=</span>705µs<span class="w"> </span>p<span class="o">(</span><span class="m">95</span><span class="o">)=</span><span class="m">820</span>.39µs
<span class="w">    </span>http_req_failed.........................................................:<span class="w"> </span><span class="m">0</span>.00%<span class="w">  </span><span class="m">0</span><span class="w"> </span>out<span class="w"> </span>of<span class="w"> </span><span class="m">2027</span>
<span class="w">    </span>http_reqs...............................................................:<span class="w"> </span><span class="m">2027</span><span class="w">   </span><span class="m">40</span>.146806/s

<span class="w">    </span>EXECUTION
<span class="w">    </span>iteration_duration......................................................:<span class="w"> </span><span class="nv">avg</span><span class="o">=</span>1s<span class="w">       </span><span class="nv">min</span><span class="o">=</span>1s<span class="w">    </span><span class="nv">med</span><span class="o">=</span>1s<span class="w">    </span><span class="nv">max</span><span class="o">=</span><span class="m">1</span>.01s<span class="w">  </span>p<span class="o">(</span><span class="m">90</span><span class="o">)=</span>1s<span class="w">    </span>p<span class="o">(</span><span class="m">95</span><span class="o">)=</span>1s
<span class="w">    </span>iterations..............................................................:<span class="w"> </span><span class="m">2027</span><span class="w">   </span><span class="m">40</span>.146806/s
<span class="w">    </span>vus.....................................................................:<span class="w"> </span><span class="m">3</span><span class="w">      </span><span class="nv">min</span><span class="o">=</span><span class="m">3</span><span class="w">         </span><span class="nv">max</span><span class="o">=</span><span class="m">50</span>
<span class="w">    </span>vus_max.................................................................:<span class="w"> </span><span class="m">50</span><span class="w">     </span><span class="nv">min</span><span class="o">=</span><span class="m">50</span><span class="w">        </span><span class="nv">max</span><span class="o">=</span><span class="m">50</span>

<span class="w">    </span>NETWORK
<span class="w">    </span>data_received...........................................................:<span class="w"> </span><span class="m">266</span><span class="w"> </span>kB<span class="w"> </span><span class="m">5</span>.3<span class="w"> </span>kB/s
<span class="w">    </span>data_sent...............................................................:<span class="w"> </span><span class="m">176</span><span class="w"> </span>kB<span class="w"> </span><span class="m">3</span>.5<span class="w"> </span>kB/s




running<span class="w"> </span><span class="o">(</span>0m50.5s<span class="o">)</span>,<span class="w"> </span><span class="m">00</span>/50<span class="w"> </span>VUs,<span class="w"> </span><span class="m">2027</span><span class="w"> </span><span class="nb">complete</span><span class="w"> </span>and<span class="w"> </span><span class="m">0</span><span class="w"> </span>interrupted<span class="w"> </span>iterations
default<span class="w"> </span>✓<span class="w"> </span><span class="o">[======================================]</span><span class="w"> </span><span class="m">00</span>/50<span class="w"> </span>VUs<span class="w">  </span>50s
</code></pre></div>
</details>
<h2 id="profiling-networked-go-applications-with-pprof">Profiling Networked Go Applications with <code>pprof</code></h2>
<p>Profiling Go applications that heavily utilize networking is crucial to identifying and resolving bottlenecks that impact performance under high-traffic scenarios. Go's built-in <code>net/http/pprof</code> package provides insights specifically beneficial for network-heavy operations. Set up continuous profiling by enabling an HTTP endpoint:</p>
<div class="highlight"><pre><span/><code><span class="kn">import</span><span class="w"> </span><span class="p">(</span>

<span class="w">    </span><span class="nx">_</span><span class="w"> </span><span class="s">"net/http/pprof"</span>

<span class="p">)</span>

<span class="c1">// ...</span>

<span class="w">    </span><span class="c1">// Start pprof in a separate goroutine.</span>
<span class="w">    </span><span class="k">go</span><span class="w"> </span><span class="kd">func</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nx">log</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="s">"pprof listening on :6060"</span><span class="p">)</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">http</span><span class="p">.</span><span class="nx">ListenAndServe</span><span class="p">(</span><span class="s">"localhost:6060"</span><span class="p">,</span><span class="w"> </span><span class="kc">nil</span><span class="p">);</span><span class="w"> </span><span class="nx">err</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="kc">nil</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nx">log</span><span class="p">.</span><span class="nx">Fatalf</span><span class="p">(</span><span class="s">"pprof server error: %v"</span><span class="p">,</span><span class="w"> </span><span class="nx">err</span><span class="p">)</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}()</span>
</code></pre></div>
<p>It's possible to inspect the application in real time, even under heavy load. To capture a CPU profile:</p>
<div class="highlight"><pre><span/><code>go<span class="w"> </span>tool<span class="w"> </span>pprof<span class="w"> </span>http://localhost:6060/debug/pprof/profile?seconds<span class="o">=</span><span class="m">30</span>
</code></pre></div>
<p>This grabs a 30-second snapshot of CPU usage. With the <code>pprof</code> HTTP server exposed, all runtime data—CPU, memory, goroutines, contention, flamegraphs—is available without pausing or restarting the application.</p>
<div class="highlight"><pre><span/><code>go<span class="w"> </span>tool<span class="w"> </span>pprof<span class="w"> </span>-http<span class="o">=</span>:7070<span class="w"> </span>cpu.prof<span class="w"> </span><span class="c1">#(1)</span>
</code></pre></div>
<ol>
<li>the actual <code>cpu.prof</code> path will be something like <code>$HOME/pprof/pprof.net-app.samples.cpu.004.pb.gz</code></li>
</ol>
<h3 id="cpu-profiling">CPU Profiling</h3>
<p>Profiling a system at rest rarely tells the full story. Real bottlenecks show up under pressure—when requests stack up, threads compete, and memory churn increases. CPU profiling during load reveals where execution time concentrates, often exposing slow serialization, inefficient handler logic, or contention between goroutines. These are the paths that quietly limit throughput and inflate latency when traffic scales.</p>
<h4 id="what-to-look-for">What to Look For</h4>
<ul>
<li>Network Serialization Hotspots: Frequent use of <code>json.Marshal</code> or similar serialization methods during network response generation.</li>
<li>Syscall Overhead: Extensive syscall usage (e.g., <code>syscall.Read</code>) suggesting inefficient socket handling or excessive blocking I/O.</li>
<li>GC Activity: High frequency of <code>runtime.gc</code> indicating inefficient memory management impacting response latency.</li>
</ul>
<p><strong>Why This Matters:</strong> Identifying and optimizing CPU-intensive operations in networking contexts reduces latency, boosts throughput, and improves reliability during traffic spikes.</p>
<h3 id="flamegraphs">Flamegraphs</h3>
<p>Flamegraphs provide a visual summary of where CPU time is spent by aggregating and collapsing stack traces into a single view. They make it easy to identify performance hotspots without digging through raw profiling data. In server applications, this often highlights issues in request handling, serialization, or blocking I/O. Under load, flamegraphs are especially useful for catching subtle inefficiencies that scale into major performance problems.</p>
<h4 id="what-to-look-for_1">What to Look For</h4>
<ul>
<li>Functions related to network I/O or data transfer that appear as wide blocks in a flamegraph often point to excessive time spent on serialization, buffering, or socket operations.</li>
<li>Deep Call Chains Deep stacks could reveal inefficient middleware or unnecessary layers in network request handling.</li>
<li>Unexpected Paths Look for unexpected serialization, reflection, or routing inefficiencies.</li>
</ul>
<p><strong>Why This Matters:</strong> Flamegraphs simplify diagnosing complex inefficiencies visually, leading to quicker optimization and reduced downtime.</p>
<h3 id="managing-garbage-collection-gc-pressure">Managing Garbage Collection (GC) Pressure</h3>
<p>Memory profiling helps identify where your application is wasting heap space, especially in network-heavy code paths. Common issues include repeated allocation of response buffers, temporary objects, or excessive use of slices and maps. These patterns often go unnoticed until they trigger GC pressure or latency under load. Profiling with <code>pprof</code> follows the same basic steps as CPU profiling, making it easy to integrate into your existing workflow.</p>
<div class="highlight"><pre><span/><code>go<span class="w"> </span>tool<span class="w"> </span>pprof<span class="w"> </span>http://localhost:6060/debug/pprof/heap
</code></pre></div>
<p>Then, again, you can view results interactively.</p>
<div class="highlight"><pre><span/><code>go<span class="w"> </span>tool<span class="w"> </span>pprof<span class="w"> </span>-http<span class="o">=</span>:7070<span class="w"> </span>mem.prof<span class="w"> </span><span class="c1">#(1)</span>
</code></pre></div>
<ol>
<li>the actual <code>mem.prof</code> path will be something like <code>$HOME/pprof/pprof.net-app.alloc_objects.alloc_space.inuse_objects.inuse_space.003.pb.gz</code></li>
</ol>
<h4 id="what-to-look-for_2">What to Look For</h4>
<ul>
<li>Frequent Temporary Buffers: High frequency of allocations in network buffers, such as repeatedly creating byte slices for each request.</li>
<li>Persistent Network Objects: Accumulation of long-lived network connections or sessions.</li>
<li>Excessive Serialization Overhead: High object creation rate due to repeated encoding/decoding of network payloads.</li>
</ul>
<p>Example: Optimizing buffer reuse using <code>sync.Pool</code> greatly reduces GC pressure during high-volume network operations.</p>
<p><strong>Why This Matters:</strong> Reducing memory churn from network activities improves response times and minimizes latency spikes caused by GC.</p>
<h3 id="identifying-cpu-bottlenecks">Identifying CPU Bottlenecks</h3>
<p>Networked applications often hit CPU limits first when pushed under sustained load. Profiling helps surface where time is actually being spent and what’s getting in the way.</p>
<h4 id="what-to-look-for_3">What to Look For</h4>
<ul>
<li>Latency Rising While Throughput Stalls: A sign the CPU is saturated, often from request processing or serialization overhead.</li>
<li>Scheduler Overhead (runtime.schedule, mcall): Too many goroutines can overwhelm the scheduler, especially when each connection gets its own handler.</li>
<li>Lock Contention: Repeated locking on shared network state or blocking channel operations slows down throughput and limits parallelism.</li>
</ul>
<p>For example, if profiling shows excessive time spent in TLS handshake routines, the fix might involve moving handshakes off the hot path or reducing handshake frequency with connection reuse.</p>
<p><strong>Why it matters:</strong> CPU bottlenecks cap your ability to scale. Fixing them is often the difference between a system that handles 5K clients and one that handles 50K.</p>
<h3 id="practicle-example-of-profiling-networked-go-applications-with-pprof">Practicle example of Profiling Networked Go Applications with <code>pprof</code></h3>
<p>To illustrate these concepts practically, our demo application integrates profiling and benchmarking tools and provides comprehensive profiling and load testing scenarios. The demo covers identifying performance bottlenecks, analyzing flame graphs, and benchmarking under various simulated network conditions.</p>
<p>Due to its significant size, <a href="../gc-endpoint-profiling/">Practicle example of Profiling Networked Go Applications with <code>prof</code></a> is a separate article.</p>
<h2 id="benchmarking-as-a-feedback-loop">Benchmarking as a Feedback Loop</h2>
<p>A single load test run means little in isolation. But if you treat benchmarking as part of your development cycle—before and after changes—you start building a performance narrative. You can see exactly how a change impacted throughput or whether it traded latency for memory overhead.</p>
<p>The Go standard library gives you <code>testing.B</code> for microbenchmarks. Combine profiling with robust integration testing as part of your CI/CD pipeline using tools like <code>Vegeta</code> and <code>k6</code>. This practice ensures early detection of regressions, continuous validation of performance enhancements, and reliable application performance maintenance under realistic production conditions.</p>









  




                
                  
</body>
</html>