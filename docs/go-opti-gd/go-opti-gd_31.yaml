- en: Managing 10K+ Concurrent Connections in Go¶
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Go中管理10K+并发连接
- en: 原文：[https://goperf.dev/02-networking/10k-connections/](https://goperf.dev/02-networking/10k-connections/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://goperf.dev/02-networking/10k-connections/](https://goperf.dev/02-networking/10k-connections/)
- en: <details class="info"><summary>Why not 100K+ or 1 Mill connection?</summary>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: <details class="info"><summary>为什么不是100K+或1百万连接？</summary>
- en: 'While framing the challenge in terms of “100K concurrent connections” is tempting,
    practical engineering often begins with a more grounded target: 10K to 20K stable,
    performant connections. This isn’t a limitation of Go itself but a reflection
    of real-world constraints: ulimit settings, ephemeral port availability, TCP stack
    configuration, and the nature of the application workload all set hard boundaries.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然将挑战定义为“100K并发连接”很有吸引力，但实际工程往往从更实际的目标开始：10K到20K稳定、性能良好的连接。这并不是Go本身的限制，而是现实世界约束的反映：ulimit设置、临时端口可用性、TCP堆栈配置以及应用程序工作负载的性质都设定了硬边界。
- en: Cloud environments introduce their own considerations. For instance, AWS Fargate
    explicitly sets both the soft and hard nofile (number of open files) limit to
    65,535, which provides more headroom for socket-intensive applications but still
    falls short of the 100K+ threshold. On EC2 instances, the practical limits depend
    on the base operating system and user configuration. By default, many Linux distributions
    impose a soft limit of 1024 and a hard limit of 65535 for nofile. Even this hard
    cap is lower than required to handle 100,000 open connections in a single process.
    Reaching higher limits requires kernel-level tuning, container runtime overrides,
    and multi-process strategies to distribute file descriptor load.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 云环境引入了它们自己的考虑因素。例如，AWS Fargate明确地将软和硬nofile（打开文件数）限制设置为65,535，这为socket密集型应用程序提供了更多的空间，但仍然低于100K+的阈值。在EC2实例上，实际限制取决于基础操作系统和用户配置。默认情况下，许多Linux发行版为nofile设定了软限制1024和硬限制65535。即使这个硬限制也低于单个进程中处理10万个打开连接所需的限制。达到更高的限制需要内核级别的调整、容器运行时覆盖和多进程策略来分配文件描述符负载。
- en: A server handling simple echo logic behaves very differently from one performing
    CPU-bound processing, structured logging, or real-time transformation. Additionally,
    platform-level tunability varies—Linux exposes granular control through sysctl,
    epoll, and reuseport, while macOS lacks many of these mechanisms. In that context,
    achieving and sustaining 10K+ concurrent connections with real workloads is a
    demanding, yet practical, benchmark.</details>
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 处理简单回声逻辑的服务器与执行CPU密集型处理、结构化日志记录或实时转换的服务器表现截然不同。此外，平台级别的可调性也各不相同——Linux通过sysctl、epoll和reuseport提供了细粒度的控制，而macOS缺乏许多这些机制。在这种情况下，在具有实际工作负载的情况下实现并维持10K+并发连接是一项具有挑战性但实用的基准。</details>
- en: Handling massive concurrency in Go is often romanticized—*"goroutines are cheap,
    just spawn them!"*—but reality gets harsher as we push towards six-digit concurrency
    levels. Serving over 10,000 concurrent sockets isn’t something you solve by scaling
    hardware alone—it requires an architecture that works with the OS, the Go runtime,
    and the network stack, not against them.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go中处理大量并发性通常被浪漫化——“goroutines很便宜，只需创建它们！”——但随着我们向六位数并发级别推进，现实变得更加严峻。仅通过扩展硬件来服务超过10,000个并发套接字并不是解决问题的方法——它需要一个与操作系统、Go运行时和网络堆栈协同工作的架构，而不是与之对抗。
- en: Embracing Go’s Concurrency Model[¶](#embracing-gos-concurrency-model "Permanent
    link")
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 接受Go的并发模型[¶](#embracing-gos-concurrency-model "永久链接")
- en: Go’s lightweight goroutines and its powerful runtime scheduler make it an excellent
    choice for scaling network applications. Goroutines consume only a few kilobytes
    of stack space, which, in theory, makes them ideal for handling tens of thousands
    of concurrent connections. However, reality forces us to think beyond just spinning
    up goroutines. While the language’s abstraction makes concurrency almost “magical,”
    achieving true efficiency at this scale demands intentional design.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Go的轻量级goroutines和其强大的运行时调度器使其成为扩展网络应用程序的绝佳选择。Goroutines仅消耗几KB的堆栈空间，从理论上讲，这使得它们非常适合处理数万个并发连接。然而，现实迫使我们必须超越仅仅启动goroutines。虽然语言的抽象使并发几乎“神奇”，但在这种规模上实现真正的效率需要有意的设计。
- en: Running a server that spawns one goroutine per connection means you’re leaning
    heavily on the runtime scheduler to juggle thousands of concurrent execution paths.
    While goroutines are lightweight, they’re not free—each one adds to memory consumption
    and introduces scheduling overhead that scales with concurrency. Thus, the first
    design pattern that should be adopted is to ensure that each connection follows
    a clearly defined lifecycle and that every goroutine performs its task as efficiently
    as possible.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 运行一个为每个连接生成一个goroutine的服务器意味着你非常依赖运行时调度器来处理数千个并发执行路径。虽然goroutine轻量级，但它们并非免费——每个goroutine都会增加内存消耗，并引入与并发性成比例的调度开销。因此，第一个应该采用的设计模式是确保每个连接遵循一个明确的生命周期，并且每个goroutine都能尽可能高效地完成任务。
- en: 'Let’s consider a basic model where we accept connections and delegate their
    handling to separate goroutines:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个基本模型，其中我们接受连接并将它们的处理委托给单独的goroutine：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Each connection is assigned its own goroutine. That approach works fine at low
    concurrency and fits Go’s model well. But once you’re dealing with tens of thousands
    of connections, the design has to account for system limits. Goroutines are cheap—but
    not free.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每个连接都分配了自己的goroutine。这种方法在低并发情况下运行良好，并且很好地适应了Go的模型。但是，一旦你处理的是成千上万的连接，设计就必须考虑到系统限制。Goroutine虽然成本低，但并非免费。
- en: Managing Concurrency at Scale[¶](#managing-concurrency-at-scale "Permanent link")
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大规模并发管理[¶](#managing-concurrency-at-scale "永久链接")
- en: It’s not enough to just accept connections; you need to control what happens
    after. Unbounded goroutine creation leads to memory growth and increased scheduler
    load. To keep the system stable, concurrency must be capped—typically using a
    semaphore or similar construct to limit how many goroutines handle active work
    at any given time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 仅接受连接是不够的；你需要控制之后发生的事情。无限制地创建goroutine会导致内存增长和调度器负载增加。为了保持系统稳定，并发性必须受到限制——通常使用信号量或类似的结构来限制在任何给定时间处理活跃工作的goroutine数量。
- en: 'For example, you might limit the number of simultaneous active connections
    before spinning up a new goroutine for each incoming connection. This strategy
    might involve a buffered channel acting as a semaphore:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可能会在为每个传入连接启动新的goroutine之前限制同时活跃的连接数。这种策略可能涉及一个充当信号量的带缓冲的channel：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This pattern not only helps prevent resource exhaustion but also gracefully
    degrades service under high load. Adjusting these limits according to your hardware
    and workload characteristics is a continuous tuning process.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式不仅有助于防止资源耗尽，还能在高负载下优雅地降低服务质量。根据你的硬件和工作负载特性调整这些限制是一个持续调优的过程。
- en: Info
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 信息
- en: We use the `connLimiter` approach here for purely illustrative purposes, as
    it clarifies the idea. In real life, you will most likely use [errgroup](https://pkg.go.dev/golang.org/x/sync/errgroup)
    to manage the goroutines amount and some `SIGINT,` and `SIGTERM` signal handling
    for graceful process termination.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用`connLimiter`方法纯粹是为了说明目的，因为它阐明了这个想法。在现实生活中，你很可能会使用[golang.org/x/sync/errgroup](https://pkg.go.dev/golang.org/x/sync/errgroup)来管理goroutine的数量，以及一些`SIGINT`和`SIGTERM`信号处理，以实现优雅的过程终止。
- en: OS-Level and Socket Tuning[¶](#os-level-and-socket-tuning "Permanent link")
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 操作系统和套接字调整[¶](#os-level-and-socket-tuning "永久链接")
- en: Before your Go application can handle more than 10,000 simultaneous connections,
    the operating system has to be prepared for that scale. On Linux, this usually
    starts with raising the limit on open file descriptors. The TCP stack also needs
    tuning—default settings often aren’t designed for high-connection workloads. Without
    these adjustments, the application will hit OS-level ceilings long before Go becomes
    the bottleneck.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的Go应用程序能够处理超过10,000个同时连接之前，操作系统必须为这种规模做好准备。在Linux上，这通常从提高打开文件描述符的限制开始。TCP堆栈也需要调整——默认设置通常不是为高连接负载设计的。如果没有这些调整，应用程序将在Go成为瓶颈之前就触及操作系统级别的上限。
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'But it doesn’t stop there. You’ll also need:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 但这还没有结束。你还需要：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`net.core.somaxconn=65535`: This controls the size of the pending connection
    queue (the backlog) for listening sockets. A small value here will cause connection
    drops when many clients attempt to connect simultaneously.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.core.somaxconn=65535`: 这项设置控制着监听套接字的待处理连接队列（即队列长度）。如果这里设置值较小，当许多客户端同时尝试连接时，可能会导致连接丢失。'
- en: '`net.ipv4.ip_local_port_range="10000 65535"`: Defines the ephemeral port range
    used for outbound connections. A wider range prevents port exhaustion when you’re
    making many outbound connections from the same machine.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.ipv4.ip_local_port_range="10000 65535"`: 定义了用于出站连接的临时端口范围。更宽的范围可以防止从同一台机器发出大量出站连接时端口耗尽。'
- en: '`net.ipv4.tcp_tw_reuse=1`: Allows reuse of sockets in `TIME_WAIT` state for
    new connections if safe. Helps reduce socket exhaustion, especially in short-lived
    TCP connections.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.ipv4.tcp_tw_reuse=1`: 允许在安全的情况下重用`TIME_WAIT`状态下的套接字进行新连接。有助于减少套接字耗尽，尤其是在短连接的TCP连接中。'
- en: '`net.ipv4.tcp_fin_timeout=15`: Reduces the time the kernel holds sockets in
    `FIN_WAIT2` after a connection is closed. Shorter timeout means faster resource
    reclamation, crucial when thousands of sockets churn per minute.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.ipv4.tcp_fin_timeout=15`: 减少了在连接关闭后内核保持套接字在`FIN_WAIT2`状态的时间。更短的超时意味着更快的资源回收，这对于每分钟有数千个套接字轮换至关重要。'
- en: Tuning these parameters helps prevent the OS from becoming the bottleneck as
    connection counts grow. On top of that, setting socket options like `TCP_NODELAY`
    can reduce latency by disabling [Nagle’s algorithm](https://en.wikipedia.org/wiki/Nagle%27s_algorithm),
    which buffers small packets by default. In Go, these options can be applied through
    the net package, or more directly via the syscall package if lower-level control
    is needed.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 调整这些参数有助于防止随着连接数增加，操作系统成为瓶颈。除此之外，设置如`TCP_NODELAY`之类的套接字选项可以通过禁用默认情况下缓冲小数据包的[Nagle算法](https://en.wikipedia.org/wiki/Nagle%27s_algorithm)来减少延迟。在Go中，这些选项可以通过net包应用，或者在需要更底层控制时，通过syscall包直接应用。
- en: 'In some cases, using Go’s `net.ListenConfig` allows you to inject custom control
    over socket creation. This is particularly useful when you need to set options
    at the time of listener creation:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，使用Go的`net.ListenConfig`允许你在创建监听器时注入自定义的套接字创建控制。这在需要设置监听器创建时的选项时特别有用：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Go Scheduler and Memory Pressure[¶](#go-scheduler-and-memory-pressure "Permanent
    link")
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Go调度器和内存压力[¶](#go-scheduler-and-memory-pressure "永久链接")
- en: Spawning 10,000 goroutines might look impressive on paper, but what matters
    is how those goroutines behave. If they’re mostly idle—blocked on I/O like network
    or disk—Go’s scheduler handles them efficiently, parking and resuming with little
    overhead. But when goroutines actively allocate memory, spin in tight loops, or
    constantly contend on channels and mutexes, things get expensive. You’ll start
    to see increased garbage collection pressure and scheduler thrashing, both of
    which erode performance.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在纸上启动10,000个goroutine可能看起来很令人印象深刻，但重要的是这些goroutine的行为。如果它们大部分是空闲的——例如在网络或磁盘I/O上阻塞——Go的调度器会高效地处理它们，以最小的开销进行暂停和恢复。但是，当goroutine积极分配内存、在紧密循环中旋转或不断在通道和互斥锁上竞争时，事情就会变得昂贵。你将开始看到垃圾收集压力增加和调度器抖动，这两者都会降低性能。
- en: Go’s garbage collector handles short-lived allocations well, but it doesn’t
    come for free. If you’re spawning goroutines that churn through memory—allocating
    per request, per message, or worse, per loop—GC pressure builds fast. The result
    isn’t just more frequent collections, but higher latency and lost CPU cycles.
    Throughput drops, and the system spends more time cleaning up than doing real
    work.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Go的垃圾收集器很好地处理了短生命周期分配，但这并不是免费的。如果你正在启动通过内存——按请求、按消息或更糟糕的是按循环分配goroutine——GC压力会迅速增加。结果不仅仅是更频繁的收集，还有更高的延迟和丢失的CPU周期。吞吐量下降，系统花费更多时间清理而不是进行实际工作。
- en: 'To manage this, you can explicitly tune the GC aggressiveness:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了管理这一点，你可以显式调整GC的积极性：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Or directly within your codebase:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 或者直接在你的代码库中：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The default value for `GOGC` is 100, meaning the GC triggers when the heap size
    doubles compared to the previous GC cycle. Lower values (like 50) mean more frequent
    but shorter GC cycles, helping control memory growth at the cost of increased
    CPU overhead.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`GOGC`的默认值是100，这意味着与之前的GC周期相比，当堆大小加倍时触发GC。较低的值（如50）意味着更频繁但更短的GC周期，这有助于控制内存增长，但会增加CPU开销。'
- en: Info
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 信息
- en: In some cases, you may need an opposite – [to increase the `GOGC` value, turn
    the GC off completely](../../01-common-patterns/gc/#gc-tuning-gogc), or prefer
    [GOMEMLIMIT=X and GOGC=off](../../01-common-patterns/gc/#gomemlimitx-and-gogcoff-configuration)
    configuration. **Do not make a decision before careful profiling!**
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，你可能需要一个相反的——[增加`GOGC`值，完全关闭GC](../../01-common-patterns/gc/#gc-tuning-gogc)，或者更喜欢[GOMEMLIMIT=X和GOGC=off](../../01-common-patterns/gc/#gomemlimitx-and-gogcoff-configuration)配置。**在仔细分析之前不要做出决定！**
- en: Optimizing Goroutine Behavior[¶](#optimizing-goroutine-behavior "Permanent link")
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化Goroutine行为[¶](#optimizing-goroutine-behavior "永久链接")
- en: 'Consider structuring your application so that goroutines block naturally rather
    than actively waiting or spinning. For example, instead of polling channels in
    tight loops, use select statements efficiently:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑将你的应用程序结构化，以便goroutines自然地阻塞，而不是积极等待或空转。例如，而不是在紧密循环中轮询通道，请有效地使用select语句：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If your goroutines must wait, prefer blocking on channels or synchronization
    primitives provided by Go, like mutexes or condition variables, instead of actively
    polling.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的goroutines必须等待，请优先选择在通道或Go提供的同步原语（如互斥锁或条件变量）上阻塞，而不是积极轮询。
- en: Pooling and Reusing Objects[¶](#pooling-and-reusing-objects "Permanent link")
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 池化和重用对象[¶](#pooling-and-reusing-objects "永久链接")
- en: 'Another crucial technique to reduce memory allocations and GC overhead [is
    using `sync.Pool`](../../01-common-patterns/object-pooling/):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '减少内存分配和垃圾回收开销的另一个关键技术[是使用 `sync.Pool`](../../01-common-patterns/object-pooling/):'
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Be careful here! It's strictly workflow-dependant, when you must return an object
    to the pool!
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里要小心！它严格依赖于工作流程，当你必须将对象返回到池中时！
- en: Reusing objects through pools reduces memory churn. With fewer allocations,
    the garbage collector runs less often and with less impact. This translates directly
    into lower latency and more predictable performance under load.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过池来重用对象可以减少内存碎片。分配得越少，垃圾回收器运行得越少，影响也越小。这直接转化为负载下的更低延迟和更可预测的性能。
- en: Connection Lifecycle Management[¶](#connection-lifecycle-management "Permanent
    link")
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连接生命周期管理[¶](#connection-lifecycle-management "永久链接")
- en: 'A connection isn’t just accepted and forgotten—it moves through a full lifecycle:
    setup, data exchange, teardown. Problems usually show up in the quiet phases.
    Idle connections that aren’t cleaned up can tie up memory and block goroutines
    indefinitely. Enforcing read and write deadlines is essential. Heartbeat messages
    help too—they give you a way to detect dead peers without waiting for the OS to
    time out.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 连接不仅仅是被接受然后被遗忘——它要经历一个完整的生命周期：设置、数据交换、拆除。问题通常出现在安静阶段。未清理的空闲连接可能会占用内存并无限期地阻塞goroutines。强制执行读取和写入截止时间至关重要。心跳消息也有帮助——它们为你提供了一种在不等待操作系统超时的情况下检测死对等的方法。
- en: In one production case, slow client responses left goroutines blocked in reads.
    Over time, they built up until the system started degrading. Adding deadlines
    and lightweight health checks fixed the leak. Goroutines no longer lingered, and
    resource usage stayed flat under load.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个实际案例中，缓慢的客户端响应导致goroutines在读取中阻塞。随着时间的推移，它们积累起来，直到系统开始退化。添加截止时间和轻量级健康检查修复了泄漏。goroutines不再滞留，负载下的资源使用保持平稳。
- en: Each connection still runs in its own goroutine—but with proper lifecycle management
    in place, scale doesn’t come at the cost of stability.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 每个连接仍然在自己的goroutine中运行——但是有了适当的生命周期管理，扩展不会以稳定性为代价。
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Inside the handler, a ticker is used to fire every few seconds, triggering
    a periodic heartbeat that keeps the connection active and responsive:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理程序内部，使用计时器每几秒触发一次，触发周期性心跳，保持连接活跃和响应：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Before reading from the client, the server sets a read deadline—if no data
    is received within that time, the operation fails, and the connection is cleaned
    up. This prevents a blocked read from stalling the goroutine indefinitely:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在从客户端读取之前，服务器设置一个读取截止时间——如果在那个时间内没有接收到数据，操作将失败，连接将被清理。这防止了阻塞读取无限期地阻止goroutine：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Likewise, before sending the heartbeat, the server sets a write deadline. If
    the client is unresponsive or the network is slow, the write will fail promptly,
    avoiding resource leakage:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在发送心跳之前，服务器设置一个写入截止时间。如果客户端无响应或网络缓慢，写入将立即失败，避免资源泄漏：
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The loop handles incoming messages and sends periodic heartbeats, with read
    and write deadlines enforcing boundaries on both sides. This setup keeps each
    connection under active supervision. Silent failures don’t linger, and the system
    avoids trading stability for performance.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 循环处理传入的消息并发送周期性心跳，通过读取和写入截止时间在双方设定边界。这种设置使每个连接都处于活跃监控之下。静默故障不会持续存在，系统避免了为了性能而牺牲稳定性。
- en: Real-World Tuning and Scaling Pitfalls[¶](#real-world-tuning-and-scaling-pitfalls
    "Permanent link")
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际调优和扩展陷阱[¶](#real-world-tuning-and-scaling-pitfalls "永久链接")
- en: Scaling to 10K+ connections is not just a matter of code—it requires anticipating
    and mitigating potential pitfalls across many layers of the stack. Beyond addressing
    memory footprint, file descriptor limits, and blocking I/O, a series of high-concurrency
    echo server tests revealed additional performance considerations under real load.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展到10K+个连接不仅仅是代码的问题——它需要预测和缓解堆栈多层中的潜在陷阱。除了解决内存占用、文件描述符限制和阻塞I/O之外，一系列高并发回声服务器测试揭示了在实际负载下的额外性能考虑因素。
- en: 'One experiment began with a simple line-based echo server. The baseline handler
    was straightforward:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个实验从一个简单的基于行的回声服务器开始。基线处理程序很简单：
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Using a tool like `tcpkali`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像`tcpkali`这样的工具：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The test ramped up to 10'000 concurrent connections. Over the 60-second run,
    it sent 2.4 MiB and received 210.3 MiB of data. Each connection averaged around
    0.4 kBps, with an aggregate throughput of 29.40 Mbps downstream and 0.33 Mbps
    upstream. This result highlighted the server’s limited responsiveness to outgoing
    data under sustained high concurrency, with substantial backpressure on `fd.Read`.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 测试增加到10,000个并发连接。在60秒的运行中，它发送了2.4 MiB的数据，接收了210.3 MiB的数据。每个连接平均约为0.4 kBps，总吞吐量为29.40
    Mbps下行和0.33 Mbps上行。这一结果突出了服务器在高并发持续负载下对外出数据的有限响应能力，以及在`fd.Read`上存在大量背压。
- en: Instrumenting and Benchmarking the Server[¶](#instrumenting-and-benchmarking-the-server
    "Permanent link")
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估和基准测试服务器[¶](#instrumenting-and-benchmarking-the-server "永久链接")
- en: Info
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 信息
- en: We use `c5.2xlarge` (8 CPU, 16 GiB) AWS instance for all these tests.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`c5.2xlarge`（8 CPU，16 GiB）AWS实例进行所有这些测试。
- en: 'To better understand system behavior under high load, Go’s built-in tracing
    facilities were enabled:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解高负载下的系统行为，启用了Go内置的跟踪功能：
- en: '[PRE15]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: After running the server and collecting traces, the command
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行服务器并收集跟踪后，命令
- en: '[PRE16]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: revealed that a significant portion of runtime was spent blocked in `fd.Read`
    and `fd.Write`, suggesting an opportunity to balance I/O operations more effectively.
    Trace analysis revealed that `fd.Read` accounted for 23% of runtime, while `fd.Write`
    consumed 75%, indicating significant write-side backpressure during echoing. Although
    `ulimit -n` was set to 65535 (AWS EC2 instance's hard limit), the system still
    encountered bottlenecks due to I/O blocking and ephemeral port range limitations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 揭示了运行时间的大部分被花费在`fd.Read`和`fd.Write`中被阻塞，这表明有机会更有效地平衡I/O操作。跟踪分析显示`fd.Read`占运行时间的23%，而`fd.Write`消耗了75%，表明在回显过程中存在显著的写入端背压。尽管`ulimit
    -n`被设置为65535（AWS EC2实例的硬限制），但由于I/O阻塞和临时端口范围限制，系统仍然遇到了瓶颈。
- en: Reducing Write Blocking with Buffered Writes[¶](#reducing-write-blocking-with-buffered-writes
    "Permanent link")
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过缓冲写入减少写入阻塞[¶](#reducing-write-blocking-with-buffered-writes "永久链接")
- en: 'Connection writes were wrapped in a `bufio.Writer` with periodic flushing instead
    of flushing after each write. The updated snippet:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 连接写入被包裹在一个`bufio.Writer`中，并定期刷新，而不是在每次写入后刷新。更新的片段：
- en: '[PRE17]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Benchmarking with:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下方法进行基准测试：
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: showed dramatic improvements—throughput increased from about 33.8 MiB to over
    1661 MiB received and 1369 MiB sent across 10,000 connections, with per-connection
    bandwidth reaching 5.3 kBps. Aggregate throughput rose to 232.28 Mbps downstream
    and 191.41 Mbps upstream. The tracing profile confirmed more balanced I/O wait
    times, even under a much heavier concurrent load.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 展示了显著的改进——通过10,000个连接，吞吐量从大约33.8 MiB增加到超过1661 MiB接收和1369 MiB发送，每个连接的带宽达到5.3
    kBps。总吞吐量上升至232.28 Mbps下行和191.41 Mbps上行。跟踪配置文件确认了在更重的并发负载下，I/O等待时间更加平衡。
- en: Handling Burst Loads and CPU-Bound Workloads[¶](#handling-burst-loads-and-cpu-bound-workloads
    "Permanent link")
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理突发负载和CPU密集型工作负载[¶](#handling-burst-loads-and-cpu-bound-workloads "永久链接")
- en: 'To evaluate the server''s behavior under extreme connection pressure, a burst
    test was executed with 30,000 connections ramping up at 5,000 per second:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估服务器在极端连接压力下的行为，执行了一个突发测试，以每秒5,000个连接的速度将连接数增加到30,000个：
- en: '[PRE19]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The server ramped up cleanly to 30,000 concurrent connections and sustained
    them for the full 60 seconds. It handled a total of 2580.3 MiB sent and 1250.9
    MiB received, maintaining an aggregate throughput of 360.75 Mbps upstream and
    174.89 Mbps downstream. Per-channel bandwidth naturally decreased to about 1.2
    kBps, but the stability across all channels and the lack of dropped connections
    pointed to effective load distribution and solid I/O handling even at scale.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器干净利落地增加到30,000个并发连接，并持续了整整60秒。它处理了总共发送2580.3 MiB和接收1250.9 MiB的数据，保持了上游360.75
    Mbps和下游174.89 Mbps的总吞吐量。每通道带宽自然下降到大约1.2 kBps，但所有通道的稳定性以及未丢失连接的情况表明，即使在规模扩大时，也有效地分配了负载并处理了稳定的I/O。
- en: 'To simulate CPU-bound workloads, the server was modified to compute a SHA256
    hash for each incoming line:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟CPU密集型工作负载，服务器被修改为对每行输入计算SHA256哈希：
- en: '[PRE20]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In this configuration, using the same 30,000-connection setup, throughput dropped
    to 1068.3 MiB sent and 799.3 MiB received. Aggregate bandwidth fell to 149.35
    Mbps upstream and 111.74 Mbps downstream, and per-connection bandwidth declined
    to around 0.7 kBps. While the server maintained full connection count and uptime,
    trace analysis revealed increased time spent in runtime.systemstack_switch and
    GC-related functions. This clearly demonstrated the impact of compute-heavy tasks
    on overall throughput and reinforced the need for careful balance between I/O
    and CPU workload when operating at high concurrency.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在此配置中，使用相同的30,000个连接设置，吞吐量降至发送1068.3 MiB和接收799.3 MiB。总带宽降至上游149.35 Mbps和下游111.74
    Mbps，每连接带宽下降到大约0.7 kBps。尽管服务器保持了完整的连接数和正常运行时间，但跟踪分析显示在runtime.systemstack_switch和GC相关函数上花费的时间增加。这清楚地证明了计算密集型任务对整体吞吐量的影响，并强调了在高并发操作时，在I/O和CPU工作负载之间进行仔细平衡的必要性。
- en: Summarizing the Technical Gains[¶](#summarizing-the-technical-gains "Permanent
    link")
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结技术收益[¶](#summarizing-the-technical-gains "永久链接")
- en: 'Benchmarking across four distinct server configurations revealed how buffering,
    concurrency scaling, and CPU-bound tasks influence performance under load:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在四种不同的服务器配置中进行基准测试，揭示了缓冲、并发扩展和CPU密集型任务如何在负载下影响性能：
- en: '| Feature | Baseline (10K, no buffer) | 10K Buffered Connections | 30K Buffered
    Connections | 30K + CPU Load (SHA256) |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 特性 | 基准（10K，无缓冲） | 10K 缓冲连接 | 30K 缓冲连接 | 30K + CPU负载（SHA256）|'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Connections handled | 10,000 | 10,000 | 30,000 | 30,000 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 处理的连接数 | 10,000 | 10,000 | 30,000 | 30,000 |'
- en: '| Data sent (60s) | 2.4 MiB | 1369.1 MiB | 2580.3 MiB | 1068.3 MiB |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 发送的数据（60秒） | 2.4 MiB | 1369.1 MiB | 2580.3 MiB | 1068.3 MiB |'
- en: '| Data received (60s) | 210.3 MiB | 1661.4 MiB | 1250.9 MiB | 799.3 MiB |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 接收的数据（60秒） | 210.3 MiB | 1661.4 MiB | 1250.9 MiB | 799.3 MiB |'
- en: '| Per-channel bandwidth | ~0.4 kBps | ~5.3 kBps | ~1.2 kBps | ~0.7 kBps |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 每通道带宽 | ~0.4 kBps | ~5.3 kBps | ~1.2 kBps | ~0.7 kBps |'
- en: '| Aggregate bandwidth (↓/↑) | 29.40 / 0.33 Mbps | 232.28 / 191.41 Mbps | 174.89
    / 360.75 Mbps | 111.74 / 149.35 Mbps |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 总带宽（↓/↑） | 29.40 / 0.33 Mbps | 232.28 / 191.41 Mbps | 174.89 / 360.75 Mbps
    | 111.74 / 149.35 Mbps |'
- en: '| Packet rate estimate (↓/↑) | 329K / 29 pkt/s | 278K / 16K pkt/s | 135K /
    32K pkt/s | 136K / 13K pkt/s |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 数据包速率估计（↓/↑） | 329K / 29 数据包/秒 | 278K / 16K 数据包/秒 | 135K / 32K 数据包/秒 | 136K
    / 13K 数据包/秒 |'
- en: '| I/O characteristics | Severe write backpressure | Balanced read/write | Efficient
    under scale | Latency from CPU contention |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| I/O特性 | 严重的写回压 | 读写平衡 | 规模下的效率 | 来自CPU竞争的延迟 |'
- en: '| CPU and GC pressure | Low | Low | Moderate | High (GC + hash compute) |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| CPU和GC压力 | 低 | 低 | 中等 | 高（GC + 哈希计算）|'
- en: Starting from the baseline of 10,000 unbuffered connections, the server showed
    limited throughput—just 2.4 MiB sent and 210.3 MiB received over 60 seconds—with
    clear signs of write-side backpressure. Introducing buffered writes with the same
    connection count unlocked over 1369 MiB sent and 1661 MiB received, improving
    throughput by more than an order of magnitude and balancing I/O wait times. Scaling
    further to 30,000 connections maintained stability and increased overall throughput,
    albeit with reduced per-connection bandwidth. When SHA256 hashing was added per
    message, total throughput dropped significantly, confirming the expected CPU bottleneck
    and reinforcing the need to factor in compute latency when designing high-concurrency,
    I/O-heavy services.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 从10,000个无缓冲连接的基线开始，服务器显示的吞吐量有限——在60秒内仅发送了2.4 MiB，接收了210.3 MiB，并且有明显的写入端背压迹象。使用相同连接数引入缓冲写入后，发送和接收的数据量分别超过1369
    MiB和1661 MiB，吞吐量提高了超过一个数量级，并平衡了I/O等待时间。进一步扩展到30,000个连接时，系统保持了稳定性，并提高了整体吞吐量，尽管每个连接的带宽有所降低。当每条消息添加SHA256哈希时，总吞吐量显著下降，证实了预期的CPU瓶颈，并强调了在设计高并发、I/O密集型服务时考虑计算延迟的必要性。
- en: These profiles serve as a concrete reference for performance-aware development,
    where transport, memory, and compute must be co-optimized for real-world scalability.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这些配置文件作为性能感知开发的实际参考，其中传输、内存和计算必须协同优化，以实现现实世界的可扩展性。
- en: As you can see, achieving even 30,000 concurrent connections with reliable performance
    is a non-trivial task. The test results demonstrated that once a workload deviates
    from a trivial echo server—for example, by adding logging, CPU-bound processing,
    or more complex read/write logic—throughput and stability can degrade rapidly.
    Performance at scale is highly dependent on workflow characteristics, such as
    I/O patterns, synchronization frequency, and memory pressure.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，即使实现30,000个并发连接并保持可靠性能也是一个非同小可的任务。测试结果表明，一旦工作负载偏离了简单的回声服务器——例如，通过添加日志记录、CPU密集型处理或更复杂的读写逻辑——吞吐量和稳定性可以迅速下降。在规模上的性能高度依赖于工作流程特征，如I/O模式、同步频率和内存压力。
- en: Taken together, these tests reinforce the need for workload-aware tuning and
    platform-specific adjustments when building high-performance, scalable networking
    systems.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 综合来看，这些测试强调了在构建高性能、可扩展的网络安全系统时，进行工作负载感知的调整和平台特定调整的必要性。
