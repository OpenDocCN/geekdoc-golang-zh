# 使用 Go 编写高性能应用程序的模式和技巧

> 原文：[`goperf.dev/`](https://goperf.dev/)

**Go 应用优化指南**是一系列关于如何使 Go 服务更快，并且这些方法真正在生产中起作用的长期系列文章。没有传说。没有不带数字的“最佳实践”。重点是理解运行时在做什么，成本从何而来，以及如何在不将你的代码库变成科学实验的情况下减少它们。 

本指南是为运行真实系统的人编写的。在持续流量下的 API、移动大量数据的后台管道以及尾部延迟重要的分布式服务。如果你的 Go 代码只在基准测试或玩具项目中运行，那么大部分内容都会觉得不必要。如果它在负载下运行，那么它可能不会。

Go 故意隐藏了其大部分底层控制。你不会得到显式的内存管理，也无法微观管理线程。你得到的是足够的可见性来推理分配、调度和 I/O 行为。结合良好的工具，这通常足以构建快速、可预测的系统。本系列文章就停留在这一领域。实用杠杆，而非理论完美。

这里的目标不是巧妙，而是编写在流量激增时保持快速且六个月后不会崩溃的枯燥代码。

## 第一部分。Go 性能常见模式

本节涵盖了在真实 Go 代码库中反复出现的性能模式。不是详尽的，也不是学术性的。只是那些小而有序的改变往往能带来回报的区域：

+   在真正有帮助的地方使用 `sync.Pool`，而不是无处不在

+   减少热点路径上的分配压力

+   结构布局、填充以及为什么缓存行为仍然很重要

+   将错误处理从快速路径中移除

+   没有意外间接成本接口

+   重复使用切片和在原地排序，而不是重新分配

每个模式都有具体的示例和测量结果。如果没有可观察的影响，它就不属于这里。

## 第二部分。Go 中的高性能网络

本部分重点介绍网络服务以及一旦并发不再是理论上的约束就会出现的限制。标准库可以让你走得很远，但默认设置并非魔法。在规模上，细节很重要。

包括以下主题：

+   高效使用 `net/http`, `net.Conn` 和连接池

+   在不资源崩溃的情况下处理数千个并发连接

+   调度器行为、`GOMAXPROCS` 和操作系统级别的机制，如 epoll 和 kqueue

+   反压、负载减轻和故障遏制

+   避免在长期连接中发生内存泄漏

+   TCP、HTTP/2、gRPC 和 QUIC 之间的权衡

本节故意更加理论化，但仍然基于可能的情况下的测试和测量。网络行为高度依赖于工作负载形状和环境细节，包括内核设置、网络拓扑、部署模式和硬件。通用规则很少。当结论依赖于假设而非保证时，这些假设会被明确地陈述。

## 第三部分。待定

范围仍在定义中，但方向是明确的：在持续负载下的运行时行为、在真实系统中工作的剖析和可观察性，以及不在基准测试中出现的故障模式。与指南的其余部分一样，重点将放在可测量的行为和权衡上，而不是通用的建议。

## 本指南面向的对象

本指南旨在针对那些关心其 Go 程序部署后行为的工程师：

+   在服务中运行后端工程师，其中延迟和吞吐量很重要

+   将 Go 推向性能关键路径的团队

+   想要理解 Go 的权衡而非猜测的开发者

+   在事故发生后而不是之前对性能进行剖析感到厌倦的人

将会有更多文章。最后，这是我最喜欢的宠物项目之一。随着系列的成长，它将保持专注于应用性能工作，而不是抽象的调优建议。如果您觉得这有用，请将其收藏并稍后回来。
