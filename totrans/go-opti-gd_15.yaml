- en: Efficient Buffering in Go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://goperf.dev/01-common-patterns/buffered-io/](https://goperf.dev/01-common-patterns/buffered-io/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Buffering is a core performance technique in systems programming. In Go, it's
    especially relevant when working with I/O—file access, network communication,
    and stream processing. Without buffering, many operations incur excessive system
    calls or synchronization overhead. Proper buffering reduces the frequency of such
    interactions, improves throughput, and smooths latency spikes.
  prefs: []
  type: TYPE_NORMAL
- en: Why Buffering Matters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Every time you read from or write to a file or socket, there’s a good chance
    you’re triggering a system call—and that’s not cheap. System calls move control
    from user space into kernel space, which means crossing a boundary that comes
    with overhead: entering kernel mode, possible context switches, interacting with
    I/O buffers, and sometimes queuing operations behind the scenes. Doing that once
    in a while is fine. Doing it thousands of times per second? That’s a problem.
    Buffering helps by batching small reads or writes into larger chunks, reducing
    how often you cross that boundary and making far better use of each syscall.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, writing to a file in a loop without buffering, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This can easily result in **10,000 separate system calls**, each carrying its
    own overhead and dragging down performance. On top of that, a flood of small writes
    tends to fragment disk operations, which puts extra pressure on I/O subsystems
    and wastes CPU cycles handling what could have been a single, efficient batch.
  prefs: []
  type: TYPE_NORMAL
- en: With Buffering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This version significantly reduces the number of system calls. The `bufio.Writer`
    accumulates writes in an internal memory buffer (typically 4KB or more). It only
    triggers a syscall when the buffer is full or explicitly flushed. As a result,
    you achieve faster I/O, reduced CPU usage, and improved performance.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: '`bufio.Writer` does not automatically flush when closed. If you forget to call
    `Flush()`, any unwritten data remaining in the buffer will be lost. Always call
    `Flush()` before closing or returning from a function, especially if the total
    written size is smaller than the buffer capacity.'
  prefs: []
  type: TYPE_NORMAL
- en: Controlling Buffer Capacity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By default, `bufio.NewWriter()` allocates a 4096-byte (4 KB) buffer. This size
    aligns with the common block size of file systems and the standard memory page
    size on most operating systems (such as Linux, BSD, and macOS). Reading or writing
    in 4 KB increments minimizes page faults, aligns with kernel read-ahead strategies,
    and maps efficiently onto underlying disk I/O operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'While 4 KB is a practical general-purpose default, it might not be optimal
    for all workloads. For high-throughput scenarios—such as streaming large files
    or generating extensive logs—a larger buffer can help reduce syscall frequency
    further:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Conversely, if latency is more critical than throughput (e.g., interactive systems
    or command-line utilities), a smaller buffer may be more appropriate, as it flushes
    data more frequently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar logic applies when reading data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Buffer size isn’t something to guess at—it’s something to measure. The ideal
    size depends on too many variables to hard-code: whether you’re writing to SSDs
    or spinning disks, how your filesystem buffers writes, how much CPU cache is available,
    and what else is competing for resources on the system. Profiling and benchmarking
    are the only reliable ways to dial it in. What works well on one setup might be
    suboptimal—or even harmful—on another.'
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking Impact
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Buffered writes and reads consistently demonstrate significant performance gains
    under load. Benchmarks measuring system calls, memory allocations, and CPU usage
    typically show that buffered I/O operations are faster and more efficient than
    unbuffered counterparts. For example, writing one million lines to disk might
    exhibit up to an order-of-magnitude improvement using `bufio.Writer` compared
    to direct `os.File.Write()` calls. The more structured and bursty your I/O operations,
    the more substantial the benefits from buffering.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="example"><summary>Show the benchmark file</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Results:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Benchmark | Iterations | Time per op (ns) | Bytes per op | Allocs per op
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| BenchmarkWriteNotBuffered-14 | 49 | 23,672,792 | 53,773 | 10,007 |'
  prefs: []
  type: TYPE_TB
- en: '| BenchmarkWriteBuffered-14 | 3241 | 379,703 | 70,127 | 10,008 |'
  prefs: []
  type: TYPE_TB
- en: When To Buffer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use buffering when:'
  prefs: []
  type: TYPE_NORMAL
- en: Performing frequent, small-sized I/O operations. Buffering groups small writes
    or reads into larger batches, which reduces the overhead of each individual operation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing syscall overhead is crucial. Fewer syscalls mean lower context-switching
    costs and improved performance, especially in I/O-heavy applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High throughput is more important than minimal latency. Buffered I/O can increase
    total data processed per second, even if it introduces slight delays in delivery.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Avoid buffering when:'
  prefs: []
  type: TYPE_NORMAL
- en: Immediate data availability and low latency are critical. Buffers introduce
    delays by design, which can be unacceptable in real-time or interactive systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buffering excessively might lead to uncontrolled memory usage. Without limits
    or proper flushing, buffers can grow large and put pressure on system memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
