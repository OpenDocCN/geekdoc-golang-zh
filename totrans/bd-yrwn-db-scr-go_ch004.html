<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <title>ch004.xhtml</title>
  <style>
  </style>
  <link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css" />
</head>
<body epub:type="bodymatter">
<section id="b-tree-crash-recovery" class="level1">
<h1>03. B-Tree &amp; Crash Recovery</h1>
<section id="b-tree-as-a-balanced-n-ary-tree" class="level2">
<h2>3.1 B-tree as a balanced n-ary tree</h2>
<section id="height-balanced-tree" class="level3">
<h3>Height-balanced tree</h3>
<p>Many practical binary trees, such as the <a href="https://build-your-own.org/redis/10_avltree">AVL tree</a> or the RB tree, are called <em>height-balanced trees</em>, meaning that the height of the tree (from root to leaves) is limited to <span class="math inline"><em>O</em>(log <em>N</em>)</span>, so a lookup is <span class="math inline"><em>O</em>(log <em>N</em>)</span>.</p>
<p>A B-tree is also height-balanced; the height is the same for all leaf nodes.</p>
</section>
<section id="generalizing-binary-trees" class="level3">
<h3>Generalizing binary trees</h3>
<p>n-ary trees can be generalized from binary trees (and vice versa). An example is the 2-3-4 tree, which is a B-tree where each node can have either 2, 3, or 4 children. The 2-3-4 tree is equivalent to the RB tree. However, we won’t go into the details because they are not necessary for understanding B-trees.</p>
<p>Visualizing a 2-level B+tree of a sorted sequence [1, 2, 3, 4, 6, 9, 11, 12].</p>
<pre><code>     [1,   4,   9]
     /     |     \
    v      v      v
[1, 2, 3] [4, 6] [9, 11, 12]</code></pre>
<p>In a B+tree, only leaf nodes contain value, keys are duplicated in internal nodes to indicate the key range of the subtree. In this example, node [1, 4, 9] indicates that its 3 subtrees are within intervals [1, 4), [4, 9), and [9, +∞). However, only 2 keys are needed for 3 intervals, so the first key (1) can be omitted and the 3 intervals become (-∞, 4), [4, 9), and (9, +∞).</p>
</section>
</section>
<section id="b-tree-as-nest-arrays" class="level2">
<h2>3.2 B-tree as nest arrays</h2>
<section id="two-level-nested-arrays" class="level3">
<h3>Two-level nested arrays</h3>
<p>Without knowing the details of the RB tree or the 2-3-4 tree, the B-tree can be understood from sorted arrays.</p>
<p>The problem with sorted arrays is the <span class="math inline"><em>O</em>(<em>N</em>)</span> update. If we split the array into <span class="math inline"><em>m</em></span> smaller non-overlapping ones, the update becomes <span class="math inline"><em>O</em>(<em>N</em>/<em>m</em>)</span>. But we have to find out which small array to update/query first. So we need another sorted array of references to smaller arrays, that’s the internal nodes in a B+tree.</p>
<pre><code>[[1,2,3], [4,6], [9,11,12]]</code></pre>
<p>The lookup cost is still <span class="math inline"><em>O</em>(log <em>N</em>)</span> with 2 binary searches. If we choose <span class="math inline"><em>m</em></span> as <span class="math inline">√<em>N</em></span>, update become <span class="math inline"><em>O</em>(√<em>N</em>)</span>, that’s as good as 2-level sorted arrays can be.</p>
</section>
<section id="multiple-levels-of-nested-arrays" class="level3">
<h3>Multiple levels of nested arrays</h3>
<p><span class="math inline"><em>O</em>(√<em>N</em>)</span> is unacceptable for databases, but if we add more levels by splitting arrays even more, the cost is further reduced.</p>
<p>Let’s say we keep splitting levels until all arrays are no larger than a constant <span class="math inline"><em>s</em></span>, we end up with <span class="math inline">log (<em>N</em>/<em>s</em>)</span> levels, and the lookup cost is <span class="math inline"><em>O</em>(log (<em>N</em>/<em>s</em>) + log (<em>s</em>))</span>, which is still <span class="math inline"><em>O</em>(log <em>N</em>)</span>.</p>
<p>For insertion and deletion, after finding the leaf node, updating the leaf node is constant <span class="math inline"><em>O</em>(<em>s</em>)</span> most of the time. The remaining problem is to maintain the invariants that nodes are not larger than <span class="math inline"><em>s</em></span> and are not empty.</p>
</section>
</section>
<section id="maintaining-a-btree" class="level2">
<h2>3.3 Maintaining a B+tree</h2>
<p>3 invariants to preserve when updating a B+tree:</p>
<ol type="1">
<li>Same height for all leaf nodes.</li>
<li>Node size is bounded by a constant.</li>
<li>Node is not empty.</li>
</ol>
<section id="growing-a-b-tree-by-splitting-nodes" class="level3">
<h3>Growing a B-tree by splitting nodes</h3>
<p>The 2nd invariant is violated by inserting into a leaf node, which is restored by splitting the node into smaller ones.</p>
<pre><code>    parent              parent
   /  |  \     =&gt;      /  | |  \
L1   L2   L6         L1  L3 L4  L6
     *                   *  *</code></pre>
<p>After splitting a leaf node, its parent node gets a new branch, which may also exceed the size limit, so it may need to be split as well. Node splitting can propagate to the root node, increasing the height by 1.</p>
<pre><code>                        new_root
                          / \
    root                 N1 N2
   /  |  \     =&gt;      /  | |  \
L1   L2   L6         L1  L3 L4  L6</code></pre>
<p>This preserves the 1st invariant, since all leaves gain height by 1 simultaneously.</p>
</section>
<section id="shrinking-a-b-tree-by-merging-nodes" class="level3">
<h3>Shrinking a B-tree by merging nodes</h3>
<p>Deleting may result in empty nodes. The 3rd invariant is restored by merging empty nodes into a sibling node. Merging is the opposite of splitting. It can also propagate to the root node, so the tree height can decrease.</p>
<p>When coding a B-tree, merging can be done earlier to reduce wasted space: you can merge a non-empty node when its size reaches a lower bound.</p>
</section>
</section>
<section id="b-tree-on-disk" class="level2">
<h2>3.4 B-Tree on disk</h2>
<p>You can already code an in-memory B-tree using these principles. But B-tree on disk requires extra considerations.</p>
<section id="block-based-allocation" class="level3">
<h3>Block-based allocation</h3>
<p>One missing detail is how to limit node size. For in-memory B+tree, you can limit the maximum number of keys in a node, the node size in bytes is not a concern, because you can allocate as many bytes as needed.</p>
<p>For disk-based data structures, there are no <code>malloc/free</code> or garbage collectors to rely on; space allocation and reuse is entirely up to us.</p>
<!-- The simplest allocator is called a _bump allocator_,
where an allocation is simply appended to the end of the file,
and deallocations are simply ignored.
This sounds just like a log, useless for our B-tree. -->
<p>Space reuse can be done with a <em>free list</em> if all allocations are of the <em>same size</em>, which we’ll implement later. For now, all B-tree nodes are the same size.</p>
</section>
<section id="copy-on-write-b-tree-for-safe-updates" class="level3">
<h3>Copy-on-write B-tree for safe updates</h3>
<p>We’ve seen 3 crash-resistant ways to update disk data: renaming files, logs, LSM-trees. The lesson is <strong>not to destroy any old data during an update</strong>. This idea can be applied to trees: make a copy of the node and modify the copy instead.</p>
<p>Insertion or deletion starts at a leaf node; after making a copy with the modification, its parent node must be updated to point to the new node, which is also done on its copy. The copying propagates to the root node, resulting in a new tree root.</p>
<ul>
<li>The original tree remains intact and is accessible from the old root.</li>
<li>The new root, with the updated copies all the way to the leaf, shares all other nodes with the original tree.</li>
</ul>
<pre><code>    d           d         D*
   / \         / \       / \
  b   e  ==&gt;  b   e  +  B*  e
 / \         / \       / \
a   c       a   c     a   C*
            original  updated</code></pre>
<p>This is a visualization of updating the leaf c. The copied nodes are in uppercase (D, B, C), while the shared subtrees are in lowercase (a, e).</p>
<p>This is called a <em>copy-on-write</em> data structure. It’s also described as <em>immutable</em>, <em>append-only</em> (not literally), or <em>persistent</em> (not related to durability). Be aware that database jargon does not have consistent meanings.</p>
<p>2 more problems remain for the copy-on-write B-tree:</p>
<ol type="1">
<li>How to find the tree root, as it changes after each update? The crash safety problem is reduced to a single pointer update, which we’ll solve later.</li>
<li>How to reuse nodes from old versions? That’s the job of a free list.</li>
</ol>
</section>
<section id="copy-on-write-b-tree-advantages" class="level3">
<h3>Copy-on-write B-tree advantages</h3>
<p>One advantage of keeping old versions around is that we got <em>snapshot isolation</em> for free. A transaction starts with a version of the tree, and won’t see changes from other versions.</p>
<p>And crash recovery is effortless; just use the last old version.</p>
<p>Another one is that it fits the multi-reader-single-writer concurrency model, and readers do not block the writer. We’ll explore these later.</p>
</section>
<section id="alternative-in-place-update-with-double-write" class="level3">
<h3>Alternative: In-place update with double-write</h3>
<p>While crash recovery is obvious in copy-on-write data structures, they can be undesirable due to the high write amplification. Each update copies the whole path (<span class="math inline"><em>O</em>(log <em>N</em>)</span>), while most in-place updates touch only 1 leaf node.</p>
<p>It’s possible to do in-place updates with crash recovery without copy-on-write:</p>
<ol type="1">
<li>Save a copy of the entire updated nodes somewhere. This is like copy-on-write, but without copying the parent node.</li>
<li><code>fsync</code> the saved copies. (Can respond to the client at this point.)</li>
<li>Actually update the data structure in-place.</li>
<li><code>fsync</code> the updates.</li>
</ol>
<p>After a crash, the data structure may be half updated, but we don’t really know. What we do is blindly apply the saved copies, so that the data structure ends with the updated state, regardless of the current state.</p>
<pre><code>| a=1 b=2 |
    ||  1. Save a copy of the entire updated nodes.
    \/
| a=1 b=2 |   +   | a=2 b=4 |
   data           updated copy
    ||  2. fsync the saved copies.
    \/
| a=1 b=2 |   +   | a=2 b=4 |
   data           updated copy (fsync&#39;ed)
    ||  3. Update the data structure in-place. But we crashed here!
    \/
| ??????? |   +   | a=2 b=4 |
   data (bad)     updated copy (good)
    ||  Recovery: apply the saved copy.
    \/
| a=2 b=4 |   +   | a=2 b=4 |
   data (new)     useless now</code></pre>
<p>The saved updated copies are called <a href="https://www.percona.com/blog/innodb-double-write/">double-write</a> in MySQL jargon. But what if the double-write is corrupted? It’s handled the same way as logs: checksum.</p>
<ul>
<li>If the checksum detects a bad double-write, ignore it. It’s before the 1st <code>fsync</code>, so the main data is in a good and old state.</li>
<li>If the double-write is good, applying it will always yield good main data.</li>
</ul>
<p>Some DBs actually store the double-writes in logs, called <a href="https://wiki.postgresql.org/wiki/Full_page_writes">physical logging</a>. There are 2 kinds of logging: <em>logical</em> and <em>physical</em>. Logical logging describes high-level operations such as inserting a key, such operations can only be applied to the DB when it’s in a good state, so only physical logging (low-level disk page updates) is useful for recovery.</p>
</section>
<section id="the-crash-recovery-principle" class="level3">
<h3>The crash recovery principle</h3>
<p>Let’s compare double-write with copy-on-write:</p>
<ul>
<li>Double-write makes updates <em>idempotent</em>; the DB can retry the update by applying the saved copies since they are full nodes.</li>
<li>Copy-on-write <em>atomically</em> switches everything to the new version.</li>
</ul>
<p>They are based on different ideas:</p>
<ul>
<li>Double-write ensures enough information to produce the new version.</li>
<li>Copy-on-write ensures that the old version is preserved.</li>
</ul>
<p>What if we save the <em>original</em> nodes instead of the updated nodes with double-write? That’s the 3rd way to recover from corruption, and it recovers to the old version like copy-on-write. We can combine the 3 ways into 1 idea: <strong>there is enough information for either the old state or the new state at any point</strong>.</p>
<p>Also, some copying is always required, so larger tree nodes are slower to update.</p>
<p>We’ll use copy-on-write because it’s simpler, but you can deviate here.</p>
</section>
</section>
<section id="what-we-learned" class="level2">
<h2>3.5 What we learned</h2>
<p>B+tree principles:</p>
<ul>
<li>n-ary tree, node size is limited by a constant.</li>
<li>Same height for all leaves.</li>
<li>Split and merge for insertion and deletion.</li>
</ul>
<p>Disk-based data structures:</p>
<ul>
<li>Copy-on-write data structures.</li>
<li>Crash recovery with double-write.</li>
</ul>
<p>We can start coding now. 3 steps to create a persistent KV based on B+tree:</p>
<ol type="1">
<li>Code the B+tree data structure.</li>
<li>Move the B+tree to disk.</li>
<li>Add a free list.</li>
</ol>
</section>
</section>
</body>
</html>
