["```go\nstateDiagram-v2\n    [*] --> Closed\n    Closed --> Open : errorRate > threshold\n    Open --> HalfOpen : resetTimeout expires\n    HalfOpen --> Closed : testSuccess >= threshold\n    HalfOpen --> Open : testFailure\n```", "```go\nflowchart TD\nsubgraph SlidingWindow [\"Sliding Window (last N intervals)\"]\n    B0((Bucket 0))\n    B1((Bucket 1))\n    B2((Bucket 2))\n    B3((Bucket 3))\n    B4((Bucket 4))\nend\n\nB0 -.-> Tick1[\"Tick(): move idx + reset bucket\"]\nTick1 --> B1\nB1 -.-> Tick2[\"Tick()\"]\nTick2 --> B2\nB2 -.-> Tick3[\"Tick()\"]\nTick3 --> B3\nB3 -.-> Tick4[\"Tick()\"]\nTick4 --> B4\nB4 -.-> Tick5[\"Tick()\"]\nTick5 --> B0\n\nB0 -.-> SumFailures[\"Sum all failures\"]\n\nSumFailures -->|Failures >= errorThreshold| OpenCircuit[\"Circuit Opens\"]\n\nOpenCircuit --> WaitReset[\"Wait resetTimeout\"]\nWaitReset --> HalfOpen[\"Move to Half-Open state\"]\n\nsubgraph HalfOpenPhase [\"Half-Open Phase\"]\n    TryCall1(\"Try Call 1\")\n    TryCall2(\"Try Call 2\")\n    TryCall3(\"Try Call 3\")\nend\n\nHalfOpen --> SuccessCheck[\"Check Successes\"]\nSuccessCheck -->|Enough successes| CloseCircuit[\"Circuit Closes\"]\nSuccessCheck -->|Failure during trial| ReopenCircuit[\"Circuit Re-Opens\"]\n\nReopenCircuit --> WaitReset\n```", "```go\n`type  slidingWindow  struct  {   buckets  []int32   size  int   idx  int   mu  sync.Mutex }` \n```", "```go\n`func  (w  *slidingWindow)  Tick()  {   w.mu.Lock()   defer  w.mu.Unlock()   w.idx  =  (w.idx  +  1)  %  w.size   atomic.StoreInt32(&w.buckets[w.idx],  0) }` \n```", "```go\n`type  CircuitState  int32  const  (   StateClosed  CircuitState  =  iota   StateOpen   StateHalfOpen )` \n```", "```go\n`type  CircuitBreaker  struct  {   failures  *slidingWindow   errorThresh  int   successThresh  int32   interval  time.Duration   resetTimeout  time.Duration   halfOpenMaxConcurrent  int32    state  CircuitState   lastOpen  time.Time   successes  int32   inFlightTrials  int32 }` \n```", "```go\n`func  NewCircuitBreaker(errThresh  int,  succThresh  int,  interval,  reset  time.Duration,  halfOpenMax  int32)  *CircuitBreaker  {   cb  :=  &CircuitBreaker{   failures:  newWindow(60),   errorThresh:  errThresh,   successThresh:  int32(succThresh),   interval:  interval,   resetTimeout:  reset,   halfOpenMaxConcurrent:  halfOpenMax,   }   go  func()  {   ticker  :=  time.NewTicker(interval)   for  range  ticker.C  {   cb.failures.Tick()   }   }()   return  cb }` \n```", "```go\n`func  (cb  *CircuitBreaker)  Allow()  bool  {   switch  atomic.LoadInt32((*int32)(&cb.state))  {   case  int32(StateClosed):   return  true   case  int32(StateOpen):   if  time.Since(cb.lastOpen)  >=  cb.resetTimeout  {   atomic.StoreInt32((*int32)(&cb.state),  int32(StateHalfOpen))   atomic.StoreInt32(&cb.successes,  0)   atomic.StoreInt32(&cb.inFlightTrials,  0)   return  true   }   return  false   case  int32(StateHalfOpen):   if  atomic.LoadInt32(&cb.inFlightTrials)  >=  cb.halfOpenMaxConcurrent  {   return  false   }   atomic.AddInt32(&cb.inFlightTrials,  1)   return  true   }   return  true }` \n```", "```go\n`func  (cb  *CircuitBreaker)  Report(success  bool)  {   if  !cb.Allow()  {   return   }   defer  func()  {   if  atomic.LoadInt32((*int32)(&cb.state))  ==  int32(StateHalfOpen)  {   atomic.AddInt32(&cb.inFlightTrials,  -1)   }   }()    switch  atomic.LoadInt32((*int32)(&cb.state))  {   case  int32(StateClosed):   if  !success  {   cb.failures.Inc()   if  int(cb.failures.Sum())  >=  cb.errorThresh  {   atomic.StoreInt32((*int32)(&cb.state),  int32(StateOpen))   cb.lastOpen  =  time.Now()   }   }    case  int32(StateHalfOpen):   if  success  {   if  atomic.AddInt32(&cb.successes,  1)  >=  cb.successThresh  {   atomic.StoreInt32((*int32)(&cb.state),  int32(StateClosed))   }   }  else  {   atomic.StoreInt32((*int32)(&cb.state),  int32(StateOpen))   cb.lastOpen  =  time.Now()   }   } }` \n```", "```go\n`breaker  :=  NewCircuitBreaker(   10,  // open after 10 failures   5,  // close after 5 half-open successes   time.Second,  // tick every second   10*time.Second,  // remain open for 10 seconds   3,  // allow up to 3 trial calls )  if  breaker.Allow()  {   success  :=  callRemoteService()   breaker.Report(success) }` \n```", "```go\nflowchart TD\n    A[Incoming Connection] --> B{Channel Full?}\n    B -- No --> C[Enqueue Request]\n    B -- Yes --> D[Drop Connection]\n```", "```go\n`// A buffered channel of size N implements passive load shedding. // When full, new requests are silently dropped (connection closed). requests  :=  make(chan  *Request,  1000)  // acceptLoop continuously accepts new connections and enqueues them // if there is capacity; otherwise, it drops excess load immediately. func  acceptLoop(ln  net.Listener)  {   for  {   conn,  err  :=  ln.Accept()   if  err  !=  nil  {   continue  // transient accept error, skip   }   req  :=  &Request{conn:  conn}    select  {   case  requests  <-  req:   // Request accepted and queued for processing.   default:   // Channel full: drop request immediately to avoid overload.   conn.Close()   }   } }` \n```", "```go\nflowchart TD\n    A[Incoming Request] --> B{CPU Load > Threshold?}\n    B -- Yes --> C[Reject Request]\n    B -- No --> D[Accept and Process]\n```", "```go\n`// shedder monitors system CPU load and decides whether to shed incoming requests. type  shedder  struct  {   maxCPU  float64  // CPU usage threshold to start shedding   checkFreq  time.Duration  // frequency to check CPU load }  // ShouldShed checks current CPU usage against the configured maximum. func  (s  *shedder)  ShouldShed()  bool  {   cpu  :=  getCPULoad()   return  cpu  >  s.maxCPU }  // startMonitor periodically evaluates CPU load and updates the global shedding flag. func  (s  *shedder)  startMonitor()  {   ticker  :=  time.NewTicker(s.checkFreq)   for  range  ticker.C  {   if  s.ShouldShed()  {   atomic.StoreInt32(&shedding,  1)  // enter shedding mode   }  else  {   atomic.StoreInt32(&shedding,  0)  // exit shedding mode   }   } }  // During request acceptance, the shedding flag is checked to actively reject overload. if  atomic.LoadInt32(&shedding)  ==  1  {   conn.Close()  // actively reject new connection }  else  {   enqueue(conn)  // accept and process normally }` \n```", "```go\nsequenceDiagram\n    participant Producer\n    participant Buffer\n    participant Consumer\n    Producer->>Buffer: Send Request\n    Buffer-->>Producer: Blocks if full\n    Buffer->>Consumer: Process Request\n```", "```go\n`// requests is a buffered channel that provides natural backpressure. // When full, producers block until space becomes available. requests  :=  make(chan  *Request,  500)  // Producer loop reads incoming connections and enqueues them. // Blocks automatically when the channel is full, applying backpressure upstream. for  conn  :=  range  incomingConns  {   req  :=  &Request{conn:  conn}   requests  <-  req  // blocks when buffer reaches 500 }` \n```", "```go\nflowchart TD\n    A[Send Request] --> B{Timeout Exceeded?}\n    B -- No --> C[Enqueue in Channel]\n    B -- Yes --> D[Cancel or Drop Request]\n```", "```go\n`// Set up a context with a strict timeout to bound enqueue latency. ctx,  cancel  :=  context.WithTimeout(context.Background(),  50*time.Millisecond) defer  cancel()  // Attempt to enqueue the request with timeout protection. select  { case  requests  <-  req:   // Request accepted into the processing queue. case  <-ctx.Done():   // Timeout exceeded before enqueue succeeded; drop or fallback.   req.conn.Close() }` \n```", "```go\nflowchart TD\n    A[Incoming Requests] --> B{Buffer Usage High?}\n    B -- Yes --> C[Increase Buffer Size]\n    C --> D[Reconfigure Channel or Queue]\n    D --> E[Continue Processing]\n\n    B -- No --> F{Buffer Usage Low?}\n    F -- Yes --> G[Decrease Buffer Size]\n    G --> D\n\n    F -- No --> E\n```", "```go\n`// DynamicBuffer wraps a buffered channel and automatically resizes it // based on usage thresholds. This enables better elasticity under varying load. type  DynamicBuffer  struct  {   mu  sync.Mutex   ch  chan  Request  // underlying buffered channel   minSize  int  // minimum buffer capacity   maxSize  int  // maximum buffer capacity   growPct  float64  // grow if usage exceeds this fraction   shrinkPct  float64  // shrink if usage falls below this fraction }  // NewDynamicBuffer initializes a dynamic buffer with initial capacity and growth rules. // It also starts a background monitor that periodically evaluates whether resizing is needed. func  NewDynamicBuffer(initial,  min,  max  int,  growPct,  shrinkPct  float64)  *DynamicBuffer  {   db  :=  &DynamicBuffer{   ch:  make(chan  Request,  initial),   minSize:  min,   maxSize:  max,   growPct:  growPct,   shrinkPct:  shrinkPct,   }   go  db.monitor()   return  db }  // Enqueue adds a request into the channel. // If the channel is full, this call blocks until space is available. func  (db  *DynamicBuffer)  Enqueue(req  Request)  {   db.mu.Lock()   ch  :=  db.ch   db.mu.Unlock()    ch  <-  req }  // Dequeue retrieves a request from the channel or aborts if the context expires. // This ensures consumers can cancel work if needed without hanging indefinitely. func  (db  *DynamicBuffer)  Dequeue(ctx  context.Context)  (Request,  bool)  {   select  {   case  req  :=  <-db.ch:   return  req,  true   case  <-ctx.Done():   return  Request{},  false   } }  // monitor runs periodically, evaluating the channel's fill ratio, // and triggers resizing if usage crosses configured thresholds. func  (db  *DynamicBuffer)  monitor()  {   ticker  :=  time.NewTicker(1  *  time.Second)   for  range  ticker.C  {   db.mu.Lock()    oldCh  :=  db.ch   cap  :=  cap(oldCh)   length  :=  len(oldCh)   usage  :=  float64(length)  /  float64(cap)    var  newSize  int   if  usage  >  db.growPct  &&  cap  <  db.maxSize  {   // If heavily loaded, double the buffer size, but cap it at maxSize   newSize  =  min(db.maxSize,  cap*2)   }  else  if  usage  <  db.shrinkPct  &&  cap  >  db.minSize  {   // If lightly loaded, shrink the buffer to half, but not below minSize   newSize  =  max(db.minSize,  cap/2)   }    if  newSize  !=  0  {   // Create a new channel with the updated size and drain old requests into it   newCh  :=  make(chan  Request,  newSize)   for  len(oldCh)  >  0  {   newCh  <-  <-oldCh   }   db.ch  =  newCh   }    db.mu.Unlock()   } }` \n```", "```go\nflowchart TD\n    A[Request Received] --> B{Overloaded?}\n    B -- Yes --> C[Return 503 + Retry-After]\n    B -- No --> D[Process Request]\n```", "```go\n`// This HTTP handler implements basic overload protection at the protocol level. // When the system is under pressure, it responds with a 503 and Retry-After header, // signaling clients to back off temporarily rather than retry aggressively.  http.HandleFunc(\"/\",  func(w  http.ResponseWriter,  r  *http.Request)  {   if  isOverloaded()  {   // Inform the client that the server is temporarily unavailable.   w.Header().Set(\"Retry-After\",  \"5\")  // suggest waiting 5 seconds before retrying   w.WriteHeader(http.StatusServiceUnavailable)   _,  _  =  w.Write([]byte(\"Service is temporarily overloaded. Please try again later.\"))   return   }    // Otherwise, proceed with request handling   process(r.Context(),  w) })` \n```", "```go\nflowchart TD\n    A[Request Received] --> B{High Load?}\n    B -- Yes --> C[Return Degraded Response]\n    B -- No --> D[Return Full Response]\n```", "```go\n``if  highLoad()  {   // degrade: return minimal response   w.Header().Set(\"Content-Type\",  \"application/json\")   w.Write([]byte(`{\"data\":\"partial\"}`))   return }`` \n```"]