- en: Benchmarking and Load Testing for Networked Go Apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://goperf.dev/02-networking/bench-and-load/](https://goperf.dev/02-networking/bench-and-load/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Before you reach for a mutex-free queue or tune your goroutine pool, step back.
    Optimization without a baseline is just guesswork. In Go applications, performance
    tuning starts with understanding how your system behaves under pressure, which
    means benchmarking it under load.
  prefs: []
  type: TYPE_NORMAL
- en: Load testing isn't just about pushing requests until things break. It's about
    simulating realistic usage patterns to extract measurable, repeatable data. That
    data anchors every optimization that follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Test App: Simulating Fast/Slow Paths and GC pressure'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To benchmark meaningfully, we need endpoints that reflect different workload
    characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: <details class="example"><summary>Show the benchmarking app</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: '`/fast`: A quick response, ideal for throughput testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/slow`: Simulates latency and contention.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/gc`: Simulate GC heavy workflow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`net/http/pprof`: Exposes runtime profiling on `localhost:6060`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Run it with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Simulating Load: Tools That Reflect Reality'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When to Use What
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Info
  prefs: []
  type: TYPE_NORMAL
- en: This is by no means an exhaustive list. The ecosystem of load-testing tools
    is broad and constantly evolving. Tools like Apache JMeter, Locust, Artillery,
    and Gatling each bring their own strengths—ranging from UI-driven test design
    to distributed execution or JVM-based scenarios. The right choice depends on your
    stack, test goals, and team workflow. The tools listed here are optimized for
    Go-based services and local-first benchmarking, but they’re just a starting point.
  prefs: []
  type: TYPE_NORMAL
- en: At a glance, `vegeta`, `wrk`, and `k6` all hammer HTTP endpoints. But they serve
    different roles depending on what you're testing, how much precision you need,
    and how complex your scenario is.
  prefs: []
  type: TYPE_NORMAL
- en: '| Tool | Focus | Scriptable | Metrics Depth | Ideal Use Case |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `vegeta` | Constant rate load generation | No (but composable) | High (histogram,
    percentiles) | Tracking latency percentiles over time; CI benchmarking |'
  prefs: []
  type: TYPE_TB
- en: '| `wrk` | Max throughput stress tests | Yes (Lua) | Medium | Measuring raw
    server capacity and concurrency limits |'
  prefs: []
  type: TYPE_TB
- en: '| `k6` | Scenario-based simulation | Yes (JavaScript) | High (VU metrics, dashboards)
    | Simulating real-world user workflows and pacing |'
  prefs: []
  type: TYPE_TB
- en: 'Use `vegeta` when:'
  prefs: []
  type: TYPE_NORMAL
- en: You need a consistent RPS load (e.g., 100 requests/sec for the 60s).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You're observing latency degradation under controlled pressure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want structured output (histograms, percentiles) for profiling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to verify local changes before deeper profiling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use `wrk` when:'
  prefs: []
  type: TYPE_NORMAL
- en: You're exploring upper-bound throughput.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want raw, fast load with minimal setup.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You’re profiling at high concurrency (e.g., 10k connections).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use `k6` when:'
  prefs: []
  type: TYPE_NORMAL
- en: You must model complex flows like login → API call → wait → logout.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You’re integrating performance tests into CI/CD.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want thresholds, pacing, and visual feedback.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these tools has a place in your benchmarking toolkit. Picking the right
    one depends on whether you're validating performance, exploring scaling thresholds,
    or simulating end-user behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Vegeta
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Vegeta](https://github.com/tsenart/vegeta) is a flexible HTTP load testing
    tool written in Go, built for generating constant request rates. This makes it
    well-suited for simulating steady, sustained traffic patterns instead of sudden
    spikes.'
  prefs: []
  type: TYPE_NORMAL
- en: We reach for Vegeta when precision matters. It maintains exact request rates
    and captures detailed latency distributions, which helps track how system behavior
    changes under load. It’s lightweight, easy to automate, and integrates cleanly
    into CI workflows—making it a reliable option for benchmarking Go services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Install:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Which endpoint(s) we are going to test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: <details class="example"><summary>Potential output</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: 'View percentiles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Generate chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: <details class="info"><summary>Testing Multiple Endpoints with Vegeta</summary>
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your goals, there are two recommended approaches for testing both
    `/fast` and `/slow` endpoints in a single run.
  prefs: []
  type: TYPE_NORMAL
- en: '**Option 1: Round-Robin Between Endpoints**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `targets.txt` with both endpoints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Requests are randomly distributed between the two endpoints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Useful for observing aggregate behavior of mixed traffic.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy to set up and analyze combined performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Option 2: Weighted Mix Using Multiple Vegeta Runs**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To simulate different traffic proportions (e.g., 80% fast, 20% slow):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then merge the results and generate a report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Gives you precise control over traffic distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Better for simulating realistic traffic mixes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables per-endpoint benchmarking when analyzed separately.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both methods are valid—choose based on whether you need simplicity or control.</details>
  prefs: []
  type: TYPE_NORMAL
- en: wrk
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[wrk](https://github.com/wg/wrk) is a high-performance HTTP benchmarking tool
    written in C. It''s designed for raw speed and concurrency, making it ideal for
    stress testing your server’s throughput and connection handling capacity.'
  prefs: []
  type: TYPE_NORMAL
- en: We use `wrk` when we want to push the system to its upper limits. It excels
    at flooding endpoints with high request volumes using multiple threads and connections.
    While it doesn’t offer detailed percentiles like `vegeta`, it's perfect for quick
    saturation tests and measuring how much traffic your Go server can handle before
    it starts dropping requests or stalling.
  prefs: []
  type: TYPE_NORMAL
- en: 'Install:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Run test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: <details class="example"><summary>Potential output</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: k6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[k6](https://k6.io) is a modern load testing tool built around scripting realistic
    client behavior in JavaScript. It’s designed for simulating time-based load profiles—ramp-up,
    steady-state, ramp-down—and supports custom flows, pacing, and threshold-based
    validation.'
  prefs: []
  type: TYPE_NORMAL
- en: We use `k6` when raw throughput isn’t enough and we need to simulate how real
    users interact with the system. It handles chained requests, models session-like
    flows, and supports stage-based testing out of the box. With rich metrics and
    seamless CI/CD integration, `k6` helps surface regressions before they reach production.
  prefs: []
  type: TYPE_NORMAL
- en: 'Install:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: <details class="example"><summary>Potential output</summary>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]</details>'
  prefs: []
  type: TYPE_NORMAL
- en: Profiling Networked Go Applications with `pprof`
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Profiling Go applications that heavily utilize networking is crucial to identifying
    and resolving bottlenecks that impact performance under high-traffic scenarios.
    Go''s built-in `net/http/pprof` package provides insights specifically beneficial
    for network-heavy operations. Set up continuous profiling by enabling an HTTP
    endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s possible to inspect the application in real time, even under heavy load.
    To capture a CPU profile:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This grabs a 30-second snapshot of CPU usage. With the `pprof` HTTP server exposed,
    all runtime data—CPU, memory, goroutines, contention, flamegraphs—is available
    without pausing or restarting the application.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: the actual `cpu.prof` path will be something like `$HOME/pprof/pprof.net-app.samples.cpu.004.pb.gz`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CPU Profiling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Profiling a system at rest rarely tells the full story. Real bottlenecks show
    up under pressure—when requests stack up, threads compete, and memory churn increases.
    CPU profiling during load reveals where execution time concentrates, often exposing
    slow serialization, inefficient handler logic, or contention between goroutines.
    These are the paths that quietly limit throughput and inflate latency when traffic
    scales.
  prefs: []
  type: TYPE_NORMAL
- en: What to Look For
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Network Serialization Hotspots: Frequent use of `json.Marshal` or similar serialization
    methods during network response generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Syscall Overhead: Extensive syscall usage (e.g., `syscall.Read`) suggesting
    inefficient socket handling or excessive blocking I/O.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GC Activity: High frequency of `runtime.gc` indicating inefficient memory management
    impacting response latency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Why This Matters:** Identifying and optimizing CPU-intensive operations in
    networking contexts reduces latency, boosts throughput, and improves reliability
    during traffic spikes.'
  prefs: []
  type: TYPE_NORMAL
- en: Flamegraphs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Flamegraphs provide a visual summary of where CPU time is spent by aggregating
    and collapsing stack traces into a single view. They make it easy to identify
    performance hotspots without digging through raw profiling data. In server applications,
    this often highlights issues in request handling, serialization, or blocking I/O.
    Under load, flamegraphs are especially useful for catching subtle inefficiencies
    that scale into major performance problems.
  prefs: []
  type: TYPE_NORMAL
- en: What to Look For
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Functions related to network I/O or data transfer that appear as wide blocks
    in a flamegraph often point to excessive time spent on serialization, buffering,
    or socket operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep Call Chains Deep stacks could reveal inefficient middleware or unnecessary
    layers in network request handling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unexpected Paths Look for unexpected serialization, reflection, or routing inefficiencies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Why This Matters:** Flamegraphs simplify diagnosing complex inefficiencies
    visually, leading to quicker optimization and reduced downtime.'
  prefs: []
  type: TYPE_NORMAL
- en: Managing Garbage Collection (GC) Pressure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Memory profiling helps identify where your application is wasting heap space,
    especially in network-heavy code paths. Common issues include repeated allocation
    of response buffers, temporary objects, or excessive use of slices and maps. These
    patterns often go unnoticed until they trigger GC pressure or latency under load.
    Profiling with `pprof` follows the same basic steps as CPU profiling, making it
    easy to integrate into your existing workflow.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Then, again, you can view results interactively.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: the actual `mem.prof` path will be something like `$HOME/pprof/pprof.net-app.alloc_objects.alloc_space.inuse_objects.inuse_space.003.pb.gz`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What to Look For
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Frequent Temporary Buffers: High frequency of allocations in network buffers,
    such as repeatedly creating byte slices for each request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Persistent Network Objects: Accumulation of long-lived network connections
    or sessions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Excessive Serialization Overhead: High object creation rate due to repeated
    encoding/decoding of network payloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example: Optimizing buffer reuse using `sync.Pool` greatly reduces GC pressure
    during high-volume network operations.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Why This Matters:** Reducing memory churn from network activities improves
    response times and minimizes latency spikes caused by GC.'
  prefs: []
  type: TYPE_NORMAL
- en: Identifying CPU Bottlenecks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Networked applications often hit CPU limits first when pushed under sustained
    load. Profiling helps surface where time is actually being spent and what’s getting
    in the way.
  prefs: []
  type: TYPE_NORMAL
- en: What to Look For
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Latency Rising While Throughput Stalls: A sign the CPU is saturated, often
    from request processing or serialization overhead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scheduler Overhead (runtime.schedule, mcall): Too many goroutines can overwhelm
    the scheduler, especially when each connection gets its own handler.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lock Contention: Repeated locking on shared network state or blocking channel
    operations slows down throughput and limits parallelism.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, if profiling shows excessive time spent in TLS handshake routines,
    the fix might involve moving handshakes off the hot path or reducing handshake
    frequency with connection reuse.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why it matters:** CPU bottlenecks cap your ability to scale. Fixing them
    is often the difference between a system that handles 5K clients and one that
    handles 50K.'
  prefs: []
  type: TYPE_NORMAL
- en: Practicle example of Profiling Networked Go Applications with `pprof`
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To illustrate these concepts practically, our demo application integrates profiling
    and benchmarking tools and provides comprehensive profiling and load testing scenarios.
    The demo covers identifying performance bottlenecks, analyzing flame graphs, and
    benchmarking under various simulated network conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Due to its significant size, [Practicle example of Profiling Networked Go Applications
    with `prof`](../gc-endpoint-profiling/) is a separate article.
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking as a Feedback Loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A single load test run means little in isolation. But if you treat benchmarking
    as part of your development cycle—before and after changes—you start building
    a performance narrative. You can see exactly how a change impacted throughput
    or whether it traded latency for memory overhead.
  prefs: []
  type: TYPE_NORMAL
- en: The Go standard library gives you `testing.B` for microbenchmarks. Combine profiling
    with robust integration testing as part of your CI/CD pipeline using tools like
    `Vegeta` and `k6`. This practice ensures early detection of regressions, continuous
    validation of performance enhancements, and reliable application performance maintenance
    under realistic production conditions.
  prefs: []
  type: TYPE_NORMAL
