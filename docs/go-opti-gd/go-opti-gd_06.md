# 内存预分配

> [https://goperf.dev/01-common-patterns/mem-prealloc/](https://goperf.dev/01-common-patterns/mem-prealloc/)

内存预分配是提高 Go 程序性能的一种简单但有效的方法，这些程序处理随时间增长的切片或映射。而不是让运行时在结构填满时——通常在不可预测的点——调整这些结构的大小，你可以预先分配所需的空间。这避免了重复分配、内部复制以及创建和丢弃中间对象时额外的 GC 压力。

在高吞吐量或延迟敏感的系统上，预分配内存可以使执行更加可预测，并有助于避免在负载下出现的性能悬崖。如果工作负载大小已知或可以合理估计，就没有理由让分配器进行猜测。

## 为什么预分配很重要

Go 的切片和映射在添加新元素时会自动增长，但这种便利也伴随着成本。当容量超出时，运行时会分配一个更大的支持数组或哈希表，并将现有数据复制过来。这种重新分配增加了内存压力，消耗 CPU 周期，并可能导致高吞吐量路径中的紧密循环停滞。在性能关键代码中——特别是在大小已知或可以估计的情况下——频繁调整大小是不必要的开销。预分配通过给运行时足够的空间来工作，避免了这些惩罚。

Go 为切片使用混合增长策略，以平衡速度和内存效率。一开始，容量随着每次扩展而加倍——2, 4, 8, 16——最小化分配次数。但一旦切片超过大约 1024 个元素，增长率会减慢到大约 25%。因此，而不是从 1024 跳到 2048，下一次分配可能增长到大约 1280。

这种转变减少了大型切片上的内存浪费，但如果最终大小已知但未预分配，会增加分配的频率。在这种情况下，使用 `make([]T, 0, expectedSize)` 是更有效的选择——它避免了重复调整大小并减少了不必要的复制。

```go
s := make([]int, 0)
for i := 0; i < 10_000; i++ {
    s = append(s, i)
    fmt.Printf("Len: %d, Cap: %d\n", len(s), cap(s))
} 
```

展示典型增长的输出：

```go
Len: 1, Cap: 1
Len: 2, Cap: 2
Len: 3, Cap: 4
Len: 5, Cap: 8
...
Len: 1024, Cap: 1024
Len: 1025, Cap: 1280 
```

## 实际预分配示例

### 切片预分配

没有预分配，每次追加操作可能会触发新的分配：

```go
// Inefficient
var result []int
for i := 0; i < 10000; i++ {
    result = append(result, i)
} 
```

这种模式会导致 Go 在切片增长时反复分配更大的底层数组，从而引起内存复制和 GC 压力。我们可以通过使用 `make` 并指定容量来避免这种情况：

```go
// Efficient
result := make([]int, 0, 10000)
for i := 0; i < 10000; i++ {
    result = append(result, i)
} 
```

如果已知切片将被完全填充，我们可以通过避免边界检查来进一步提高效率：

```go
// Efficient
result := make([]int, 10000)
for i := range result {
    result[i] = i
} 
```

### 映射预分配

映射（Map）的增长方式类似。默认情况下，Go 不知道你会添加多少元素，因此它会根据需要调整底层结构的大小。

```go
// Inefficient
m := make(map[int]string)
for i := 0; i < 10000; i++ {
    m[i] = fmt.Sprintf("val-%d", i)
} 
```

从 Go 1.11 版本开始，你也可以预分配 `map` 容量：

```go
// Efficient
m := make(map[int]string, 10000)
for i := 0; i < 10000; i++ {
    m[i] = fmt.Sprintf("val-%d", i)
} 
```

这有助于运行时预先分配足够的内部存储，避免重新哈希和调整大小的成本。

## 基准测试影响

这里是一个简单的基准测试，比较将元素追加到预分配的切片与追加到零容量切片：

<details class="example"><summary>显示基准测试文件</summary>

```go
package perf

import (
    "testing"
)

func BenchmarkAppendNoPrealloc(b *testing.B) {
    for b.Loop() {
        var s []int
        for j := 0; j < 10000; j++ {
            s = append(s, j)
        }
    }
}

func BenchmarkAppendWithPrealloc(b *testing.B) {
    for b.Loop() {
        s := make([]int, 0, 10000)
        for j := 0; j < 10000; j++ {
            s = append(s, j)
        }
    }
} 
```</details>

你通常会观察到预分配将分配减少到每次操作一个，并显著提高吞吐量。

| 基准测试 | 迭代次数 | 每次操作时间（纳秒） | 每次操作字节数 | 每次操作分配数 |
| --- | --- | --- | --- | --- |
| 基准测试：不带预分配的追加-14 | 41,727 | 28,539 | 357,626 | 19 |
| 基准测试：带预分配的追加-14 | 170,154 | 7,093 | 81,920 | 1 |

## 预分配的时机

在以下情况下预分配：

+   切片或映射中的元素数量已知或可合理预测。预先分配内存可以避免随着数据结构增长而重复调整大小的成本。

+   你的应用程序涉及紧密的循环或高吞吐量数据处理。预分配减少了每次迭代的开销，并有助于在负载下保持稳定的性能。

+   最小化垃圾收集开销对你的应用程序性能至关重要。更少的分配意味着垃圾收集器的工作量更少，从而降低延迟并提高行为的一致性。

在以下情况下避免预分配：

+   数据大小高度可变且不可预测。如果输入大小波动很大，任何固定大小的预分配都可能导致要么太小（导致重新分配），要么太大（浪费内存）。

+   过度分配可能导致显著的内存浪费。预留比所需更多的内存会增加应用程序的内存占用，并可能对缓存局部性产生负面影响或触发不必要的垃圾收集活动。

+   你正在过早地进行优化。始终使用性能分析来验证。预分配是有效的，但只有当它解决你工作负载中的真实瓶颈或分配热点时。
