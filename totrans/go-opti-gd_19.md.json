["```go\n`package  main  // pprof-start import  ( // pprof-end   \"flag\"   \"fmt\"   \"log\"   \"math/rand/v2\"   \"net/http\" // pprof-start   _  \"net/http/pprof\" // pprof-end   \"os\"   \"os/signal\"   \"time\" // pprof-start ) // pprof-end  var  (   fastDelay  =  flag.Duration(\"fast-delay\",  0,  \"Fixed delay for fast handler (if any)\")   slowMin  =  flag.Duration(\"slow-min\",  1*time.Millisecond,  \"Minimum delay for slow handler\")   slowMax  =  flag.Duration(\"slow-max\",  300*time.Millisecond,  \"Maximum delay for slow handler\")   gcMinAlloc  =  flag.Int(\"gc-min-alloc\",  50,  \"Minimum number of allocations in GC heavy handler\")   gcMaxAlloc  =  flag.Int(\"gc-max-alloc\",  1000,  \"Maximum number of allocations in GC heavy handler\") )  func  randRange(min,  max  int)  int  {   return  rand.IntN(max-min)  +  min }  func  fastHandler(w  http.ResponseWriter,  r  *http.Request)  {   if  *fastDelay  >  0  {   time.Sleep(*fastDelay)   }   fmt.Fprintln(w,  \"fast response\") }  func  slowHandler(w  http.ResponseWriter,  r  *http.Request)  {   delayRange  :=  int((*slowMax  -  *slowMin)  /  time.Millisecond)   delay  :=  time.Duration(randRange(1,  delayRange))  *  time.Millisecond   time.Sleep(delay)   fmt.Fprintf(w,  \"slow response with delay %d ms\\n\",  delay.Milliseconds()) }  // heavy-start var  longLivedData  [][]byte  func  gcHeavyHandler(w  http.ResponseWriter,  r  *http.Request)  {   numAllocs  :=  randRange(*gcMinAlloc,  *gcMaxAlloc)   var  data  [][]byte   for  i  :=  0;  i  <  numAllocs;  i++  {   // Allocate 10KB slices. Occasionally retain a reference to simulate long-lived objects.   b  :=  make([]byte,  1024*10)   data  =  append(data,  b)   if  i%100  ==  0  {  // every 100 allocations, keep the data alive   longLivedData  =  append(longLivedData,  b)   }   }   fmt.Fprintf(w,  \"allocated %d KB\\n\",  len(data)*10) } // heavy-end  func  main()  {   flag.Parse()    http.HandleFunc(\"/fast\",  fastHandler)   http.HandleFunc(\"/slow\",  slowHandler)   http.HandleFunc(\"/gc\",  gcHeavyHandler)  // pprof-start // ...    // Start pprof in a separate goroutine.   go  func()  {   log.Println(\"pprof listening on :6060\")   if  err  :=  http.ListenAndServe(\"localhost:6060\",  nil);  err  !=  nil  {   log.Fatalf(\"pprof server error: %v\",  err)   }   }() // pprof-end    // Create a server to allow for graceful shutdown.   server  :=  &http.Server{Addr:  \":8080\"}    go  func()  {   log.Println(\"HTTP server listening on :8080\")   if  err  :=  server.ListenAndServe();  err  !=  nil  &&  err  !=  http.ErrServerClosed  {   log.Fatalf(\"HTTP server error: %v\",  err)   }   }()    // Graceful shutdown on interrupt signal.   sigCh  :=  make(chan  os.Signal,  1)   signal.Notify(sigCh,  os.Interrupt)   <-sigCh   log.Println(\"Shutting down server...\")   if  err  :=  server.Shutdown(nil);  err  !=  nil  {   log.Fatalf(\"Server Shutdown Failed:%+v\",  err)   }   log.Println(\"Server exited\") }` \n```", "```go\n`go  run  main.go` \n```", "```go\n`go  install  github.com/tsenart/vegeta@latest` \n```", "```go\n`echo  \"GET http://localhost:8080/slow\"  >  targets.txt` \n```", "```go\n`vegeta  attack  -rate=100  -duration=30s  -targets=targets.txt  |  tee  results.bin  |  vegeta  report` \n```", "```go\n`>  vegeta  attack  -rate=100  -duration=30s  -targets=targets.txt  |  tee  results.bin  |  vegeta  report Requests  [total,  rate,  throughput]  3000,  100.04,  100.03 Duration  [total,  attack,  wait]  29.989635542s,  29.989108333s,  527.209µs Latencies  [mean,  50,  95,  99,  max]  524.563µs,  504.802µs,  793.997µs,  1.47362ms,  7.351541ms Bytes  In  [total,  mean]  42000,  14.00 Bytes  Out  [total,  mean]  0,  0.00 Success  [ratio]  100.00% Status  Codes  [code:count]  200:3000 Error  Set:` \n```", "```go\n`vegeta  report  -type='hist[0,10ms,50ms,100ms,200ms,500ms,1s]'  <  results.bin` \n```", "```go\n`vegeta  plot  <  results.bin  >  plot.html` \n```", "```go\n`cat  >  targets.txt  <<EOF GET http://localhost:8080/fast GET http://localhost:8080/slow EOF` \n```", "```go\n`vegeta  attack  -rate=50  -duration=30s  -targets=targets.txt  |  tee  mixed-results.bin  |  vegeta  report  -type='hist[0,50ms,100ms,200ms,500ms,1s,2s]'` \n```", "```go\n`# Send 80% of requests to /fast vegeta  attack  -rate=40  -duration=30s  -targets=<(echo  \"GET http://localhost:8080/fast\")  >  fast.bin  &  # Send 20% of requests to /slow vegeta  attack  -rate=10  -duration=30s  -targets=<(echo  \"GET http://localhost:8080/slow\")  >  slow.bin  &  wait` \n```", "```go\n`vegeta  encode  fast.bin  slow.bin  >  combined.bin vegeta  report  -type='hist[0,50ms,100ms,200ms,500ms,1s,2s]'  <  combined.bin` \n```", "```go\n`brew  install  wrk  # or build from source` \n```", "```go\n`wrk  -t4  -c100  -d30s  http://localhost:8080/fast` \n```", "```go\n`>  wrk  -t4  -c100  -d30s  http://localhost:8080/fast Running  30s  test  @  http://localhost:8080/fast   4  threads  and  100  connections   Thread  Stats  Avg  Stdev  Max  +/-  Stdev   Latency  1.29ms  255.31us  5.24ms  84.86%   Req/Sec  19.30k  565.16  21.93k  77.92%   2304779  requests  in  30.00s,  287.94MB  read Requests/sec:  76823.88 Transfer/sec:  9.60MB` \n```", "```go\n`brew  install  k6` \n```", "```go\n`// script.js import  http  from  'k6/http'; import  {  sleep  }  from  'k6';  export  const  options  =  {   stages:  [   {  duration:  '10s',  target:  50  },   {  duration:  '30s',  target:  50  },   {  duration:  '10s',  target:  0  },   ], };  export  default  function  ()  {   http.get('http://localhost:8080/fast');   sleep(1); }` \n```", "```go\n`k6  run  script.js` \n```", "```go\n`>  k6  run  script.js    /\\  Grafana  /‾‾/   /\\  /  \\  |\\  __  /  /   /  \\/  \\  |  |/  /  /  ‾‾\\   /  \\  |  (  |  (‾)  |   /  __________  \\  |_|\\_\\  \\_____/    execution:  local   script:  script.js   output:  -    scenarios:  (100.00%)  1  scenario,  50  max  VUs,  1m20s  max  duration  (incl.  graceful  stop):   *  default:  Up  to  50  looping  VUs  for  50s  over  3  stages  (gracefulRampDown:  30s,  gracefulStop:  30s)     █  TOTAL  RESULTS    HTTP   http_req_duration.......................................................:  avg=495.55µs  min=116µs  med=449µs  max=5.49ms  p(90)=705µs  p(95)=820.39µs   {  expected_response:true  }............................................:  avg=495.55µs  min=116µs  med=449µs  max=5.49ms  p(90)=705µs  p(95)=820.39µs   http_req_failed.........................................................:  0.00%  0  out  of  2027   http_reqs...............................................................:  2027  40.146806/s    EXECUTION   iteration_duration......................................................:  avg=1s  min=1s  med=1s  max=1.01s  p(90)=1s  p(95)=1s   iterations..............................................................:  2027  40.146806/s   vus.....................................................................:  3  min=3  max=50   vus_max.................................................................:  50  min=50  max=50    NETWORK   data_received...........................................................:  266  kB  5.3  kB/s   data_sent...............................................................:  176  kB  3.5  kB/s     running  (0m50.5s),  00/50  VUs,  2027  complete  and  0  interrupted  iterations default  ✓  [======================================]  00/50  VUs  50s` \n```", "```go\n`import  (    _  \"net/http/pprof\"  )  // ...    // Start pprof in a separate goroutine.   go  func()  {   log.Println(\"pprof listening on :6060\")   if  err  :=  http.ListenAndServe(\"localhost:6060\",  nil);  err  !=  nil  {   log.Fatalf(\"pprof server error: %v\",  err)   }   }()` \n```", "```go\n`go  tool  pprof  http://localhost:6060/debug/pprof/profile?seconds=30` \n```", "```go\n`go  tool  pprof  -http=:7070  cpu.prof  #(1)` \n```", "```go\n`go  tool  pprof  http://localhost:6060/debug/pprof/heap` \n```", "```go\n`go  tool  pprof  -http=:7070  mem.prof  #(1)` \n```"]