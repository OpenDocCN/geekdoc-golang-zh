# 内存预分配

> 原文：[`goperf.dev/01-common-patterns/mem-prealloc/`](https://goperf.dev/01-common-patterns/mem-prealloc/)

内存预分配是提高 Go 程序性能的一种简单而有效的方法，这些程序处理随时间增长的切片或映射。而不是让运行时在它们填满时调整这些结构的大小——通常在不可预测的点——你预先分配所需的空间。这避免了重复分配、内部复制以及创建和丢弃中间对象时额外的 GC 压力。

在高吞吐量或延迟敏感的系统里，预分配内存可以使执行更加可预测，并有助于避免在负载下出现的性能悬崖。如果工作负载的大小已知或可以合理估计，就没有理由让分配器去猜测。

## 为什么预分配很重要

Go 的切片和映射在添加新元素时会自动增长，但这种便利性是有代价的。当容量超出时，运行时会分配一个更大的支持数组或哈希表，并将现有数据复制过来。这种重新分配增加了内存压力，消耗 CPU 周期，并可能导致高吞吐量路径中的紧密循环停滞。在性能关键代码中——特别是在大小已知或可以估计的情况下——频繁的调整大小是不必要的开销。预分配通过为运行时提供足够的操作空间来避免这些惩罚，从而避免中断。

Go 使用混合增长策略来平衡切片的速度和内存效率。一开始，容量随着每次扩展而加倍——2, 4, 8, 16——最小化分配次数。但一旦切片超过大约 1024 个元素，增长率会减慢到大约 25%。所以，而不是从 1024 跳到 2048，下一次分配可能会增长到大约 1280。

这种变化减少了大型切片上的内存浪费，但如果最终大小已知但未预分配，则会增加分配的频率。在这些情况下，使用`make([]T, 0, expectedSize)`是更有效的选择——它避免了重复调整大小和不必要的复制。

```go
`s  :=  make([]int,  0) for  i  :=  0;  i  <  10_000;  i++  {   s  =  append(s,  i)   fmt.Printf("Len: %d, Cap: %d\n",  len(s),  cap(s)) }` 
```

展示典型增长的输出：

```go
`Len: 1, Cap: 1 Len: 2, Cap: 2 Len: 3, Cap: 4 Len: 5, Cap: 8 ... Len: 1024, Cap: 1024 Len: 1025, Cap: 1280` 
```

## 实际预分配示例

### 切片预分配

没有预分配的情况下，每次追加操作可能会触发新的分配：

```go
`// Inefficient var  result  []int for  i  :=  0;  i  <  10000;  i++  {   result  =  append(result,  i) }` 
```

这种模式会导致 Go 在切片增长时反复分配更大的底层数组，从而导致内存复制和 GC 压力。我们可以通过使用指定容量的`make`来避免这种情况：

```go
`// Efficient result  :=  make([]int,  0,  10000) for  i  :=  0;  i  <  10000;  i++  {   result  =  append(result,  i) }` 
```

如果已知切片将被完全填充，我们可以通过避免边界检查来提高效率：

```go
`// Efficient result  :=  make([]int,  10000) for  i  :=  range  result  {   result[i]  =  i }` 
```

### 映射预分配

映射（map）的增长方式类似。默认情况下，Go 不知道你会添加多少元素，所以它会根据需要调整底层结构的大小。

```go
`// Inefficient m  :=  make(map[int]string) for  i  :=  0;  i  <  10000;  i++  {   m[i]  =  fmt.Sprintf("val-%d",  i) }` 
```

从 Go 1.11 版本开始，你也可以预分配`map`的容量：

```go
`// Efficient m  :=  make(map[int]string,  10000) for  i  :=  0;  i  <  10000;  i++  {   m[i]  =  fmt.Sprintf("val-%d",  i) }` 
```

这有助于运行时预先分配足够的内部存储，避免重新哈希和调整大小的成本。

## 基准测试影响

这里有一个简单的基准测试，比较预分配切片与零容量切片的追加操作：

<details class="example"><summary>显示基准测试文件</summary>

```go
`package  perf  import  (   "testing" )  func  BenchmarkAppendNoPrealloc(b  *testing.B)  {   for  b.Loop()  {   var  s  []int   for  j  :=  0;  j  <  10000;  j++  {   s  =  append(s,  j)   }   } }  func  BenchmarkAppendWithPrealloc(b  *testing.B)  {   for  b.Loop()  {   s  :=  make([]int,  0,  10000)   for  j  :=  0;  j  <  10000;  j++  {   s  =  append(s,  j)   }   } }` 
```</details>

你通常会观察到预分配将分配减少到每次操作一个，并显著提高吞吐量。

| 基准测试 | 迭代次数 | 每次操作时间（纳秒） | 每次操作字节数 | 每次操作分配数 |
| --- | --- | --- | --- | --- |
| 基准测试：不带预分配的追加操作-14 | 41,727 | 28,539 | 357,626 | 19 |
| 基准测试：带预分配的追加操作-14 | 170,154 | 7,093 | 81,920 | 1 |

## 预分配的时机

在以下情况下预分配：

+   切片或映射中的元素数量是已知的或可以合理预测的。提前分配内存可以避免随着数据结构增长而重复调整大小的成本。

+   你的应用程序涉及紧密循环或高吞吐量数据处理。预分配减少了每次迭代的开销，并有助于在负载下保持稳定的性能。

+   最小化垃圾收集开销对你的应用程序性能至关重要。更少的分配意味着垃圾收集器的工作量更少，从而降低延迟并提高行为的一致性。

在以下情况下避免预分配：

+   数据大小高度可变且不可预测。如果输入大小波动很大，任何固定大小的预分配都可能导致要么太小（导致重新分配），要么太大（浪费内存）。

+   过度分配可能导致显著的内存浪费。预留比所需更多的内存会增加应用程序的足迹，并可能对缓存局部性产生负面影响或触发不必要的 GC 活动。

+   你过早地进行优化。始终通过性能分析来验证。预分配内存是有效的，但仅当它解决你的工作负载中的实际瓶颈或分配热点时。
